{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# считываем датасет\n",
    "f = open('C:\\Users\\horch\\Desktop\\Data mining\\Course 5\\smsspamcollection\\SMSSpamCollection.txt', 'r')\n",
    "coll = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# создаем список меток\n",
    "labels = []\n",
    "for text in coll:\n",
    "    if text.split('\\t')[0] == 'spam':\n",
    "        labels.append(1)\n",
    "    else: labels.append(0) \n",
    "        \n",
    "# создаем список текстов\n",
    "texts =[]\n",
    "for word in coll:\n",
    "    texts.append(word.split('\\t')[1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.933348526858\n"
     ]
    }
   ],
   "source": [
    "print cross_val_score(LogisticRegression(random_state=2), X, labels, cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_text = ['FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB',\n",
    "            'FreeMsg: Txt: claim your reward of 3 hours talk time',\n",
    "            'Have you visited the last lecture on physics?',\n",
    "            'Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$',\n",
    "            'Only 99$']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "    ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "clf_pipeline = Pipeline(\n",
    "            [(\"vectorizer\", CountVectorizer()),\n",
    "            (\"classifier\", LogisticRegression())]\n",
    "        )\n",
    "\n",
    "\n",
    "clf_pipeline.fit(texts, labels)\n",
    "\n",
    "print clf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ans2 = clf_pipeline.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvs = []\n",
    "for i in [(2,2), (3,3), (1,3)]:\n",
    "    X = CountVectorizer(ngram_range=i).fit_transform(texts)\n",
    "    cvs.append(cross_val_score(LogisticRegression(), X, labels, cv=10, scoring = 'f1').mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.82242206641871329, 0.72501615554673771, 0.92513825586488374]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_cvs = []\n",
    "for i in [(2,2), (3,3), (1,3)]:\n",
    "    X = CountVectorizer(ngram_range=i).fit_transform(texts)\n",
    "    nb_cvs.append(cross_val_score(MultinomialNB(), X, labels, cv=10, scoring = 'f1').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.64545540135589818, 0.37862343087618666, 0.88790546088949929]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.648367371228\n"
     ]
    }
   ],
   "source": [
    "X = TfidfVectorizer(ngram_range=(1,3)).fit_transform(texts)\n",
    "print cross_val_score(LogisticRegression(), X, labels, cv=10, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(cvs[2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_answer1(num):\n",
    "  with open(\"spam1.txt\", \"w\") as ff:\n",
    "    ff.write(str(num))\n",
    "def write_answer2(num):\n",
    "  with open(\"spam2.txt\", \"w\") as ff:\n",
    "    ff.write(str(num))\n",
    "def write_answer3(num):\n",
    "  with open(\"spam3.txt\", \"w\") as ff:\n",
    "    ff.write(str(num))\n",
    "def write_answer4(num):\n",
    "  with open(\"spam4.txt\", \"w\") as ff:\n",
    "    ff.write(str(num))\n",
    "    \n",
    "write_answer1(0.9) \n",
    "write_answer2(ans2)\n",
    "write_answer3(cvs)\n",
    "write_answer4(nb_cvs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-graded Assignment: Эксперименты с моделью\n",
    "\n",
    "На прошлой неделе вы поучаствовали в соревновании на kaggle и, наверняка, большинство успешно справилось с прохождением baseline, а значит пора двигаться дальше - заняться оптимизацией модели, провести серию экспериментов и построить сильное финальное решения.\n",
    "\n",
    "В этом задании вам нужно провести ряд эскпериментов, оценить качество полученных в процессе экспериментирования моделей и выбрать лучшее решение. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание будет оцениваться на основании загруженного jupyther notebook и развернутых ответов на поставленные вопросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\horch\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\horch\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, recall_score, precision_score, f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# загружаем данные\n",
    "data = pd.read_csv('C:\\\\Users\\\\horch\\\\Desktop\\\\Local_data\\\\orange_small_churn_train_data.csv', sep = ',')\n",
    "data.drop('ID', axis = 1, inplace = True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обрабатываем данные для модели\n",
    "empty_cols = data.columns[np.where(data.count() == 0)]\n",
    "for cols in empty_cols:\n",
    "    data.drop(cols, axis =1, inplace = True)\n",
    "         \n",
    "cat_features = data.iloc[:, 174:]\n",
    "num_features = data.drop(cat_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newfeature = cat_features.columns+'_n'\n",
    "for i in range(len(cat_features.columns)-1):\n",
    "    cat_features[newfeature[i]] = cat_features[cat_features.columns[i]].map(cat_features.groupby(cat_features.columns[i]).size())\n",
    "encoding_cat_data = cat_features.iloc[:,39:]\n",
    "data_new = pd.concat([num_features,encoding_cat_data], axis = 1)\n",
    "\n",
    "data_mean = data_new[data_new.columns[0]].fillna(data_new.mean(axis=0)[0])\n",
    "for i in range(len(data_new.columns)-1):\n",
    "    data_mean = np.vstack((data_mean,data_new[data_new.columns[i+1]].fillna(data_new.mean(axis=0)[i+1]))) \n",
    "data_new_mean = pd.DataFrame(data_mean.transpose(),columns=data_new.columns)\n",
    "data_new_mean['labels'] = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция для построения графиков кривых обучения\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,  scoring='roc_auc')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXl8VNX5/9/PTHYSwmrYCe5ssqOIaFK1xZWq9OuCXfhV\nqQut1oriUmttsfit3ypa+0Vrra2loHX5aivVohB3FLQoZVNEdpRFgQRIyCTP749zZ3IzmUmGkMn6\nvF+v+5o7555773NvMudzzvOcRVQVwzAMw6iLQFMbYBiGYbQMTDAMwzCMhDDBMAzDMBLCBMMwDMNI\nCBMMwzAMIyFMMAzDMIyEMMEw6o2I/FNEvtvUdjQnRGSAiCwVEWnk+64XkTO8/VtF5NHGvH9TIyKz\nReSnDXCddBFZLSJdG8Ku1oYJRgvEXzg0Jap6lqr+KRnXFpH2InK/iGwUkRIR+dT73iUZ92tAfgHc\nq74BTiJyiYi8KyL7RGS7t39NskRFVe9W1SsO9zoiki8iKiIpteS5U0TKvb9RiYisEpGLDvfeddj1\nPRF505+mqlep6i8O99qqWgY8Bkw/3Gu1RkwwjJjUVkg0wr3TgFeBgcB4oD0wBtgJjK7H9RrlWUSk\nO1AI/J8v7SfALODXQDcgD7gKGAukxblOMOnGNixPqmq2qmYD1wN/EZG8pjbqMPgr8F0RSW9qQ5od\nqmpbC9uA9cAZcY6dCywDdgNvAyf4jk0HPgWKgZXABb5j3wPeAu4DdgG/9NLeBO4FvgI+A87ynVME\nXOE7v7a8/YDXvXu/AjwE/CXOM1wBfAFk1/IOFDja9/1x4JfefgGwGbgZ+Bx4AlgFnOvLnwLsAIZ7\n30/y3tdu4EOgIOrdrPNs/wyYFMem7wCv+L7nAvuAi+r4ez4O/C8w38t/BnAO8G9gL7AJuDPqnG8D\nG7y/1W3+/wngTv+7rePZinCtore85/sX0MU7ttF7zyXeNiaG7dXu5aVtB072fb8SWAt8CbwA9PAd\nOxlYAuzxPv3n1XjvQH+gFKjwbNpdy9//J54t24DJvut2Bv7uvdsluP/1N6Oe4RPgtKb+rTe3zVoY\nrQgRGYZrTv8A96N4GHjBV1P6FBiHK8h+jqsJdvdd4kTcDzQPmOFLWwN0Af4b+EMtrpTa8v4VeM+z\n605cgRePM4CXVLWk7qeOSzegE9AXmALMBS71Hf8GsFNVPxCRnsCLuIKjE3Aj8IyIdBWRdsADOPHL\nwRVwy+LcczDu+cOMAdKB5xOw9zLcO8/BCe8+nAB1wInH1SLyTXBxEpzAfBvogXunvWJdtLZni7r3\nZOAIXKvnRi/9VO+zg7oWxDu1PYA4zvGusdJL+xrwK+C/gO44kZvnHevk2faA9wy/AV4Ukc7x3ruq\nrsK10N7xbOoQx5xuuP/znsD3gYdEpKN37CHc++0GfNfbolkFDKntedsiJhitiynAw6r6rqpWqIsv\nlOFqmKjq31R1q6pWquqTuFqU38WzVVUfVNWQqh7w0jao6u9VtQL4E+5HH8/dEDOviPQBRgF3qOpB\nVX0TV9OMR2dcrfBwqAR+pqpl3rP8FThfRLK845fhRATgcmC+qs733s0CYClwtu9ag0QkU1W3qeqK\nOPfsgKsNh+mCE6VQOEFE3haR3SJyQERO9eV9XlXf8u5fqqpFqrrc+/6RZ+tpXt6JwD9U9XV1Pvef\nejbGoq5nA/ijqn7svaengKFxrhWP/xKR3bga/wvA3aq62zs2CXhMVT/wbL0FGCMi+Tgh/ERVn/D+\n5+YCq4HzvHMTfe+xKAfuUtVyVZ3v2Xac5+67CPe/sV9VV+L+V6Mpxv09DR8mGK2LvsBPvAJpt/cj\n7o2rhSIi3xGRZb5jg3CFWphNMa75eXhHVfd7u9lx7h8vbw/gS19avHuF2YUTm8Nhh6qW+uxZi6s1\nnueJxvk4EQH33r4V9d5OAbqr6j7gYlytdpuIvCgix8e551e4FoL/Obr4YyiqerJXK95F9d9ftfch\nIieKyCIR2SEie7z7h/9WPfz5PRt3xbEp7rP58nzu299P/L9vPJ5S1Q6q2g44CviOiPzAZ+sGn60l\nnq09o495bAB6HuJ7j8Uuv1BT9Vxdce5I//uO9b+Yg3PhGT5MMFoXm4AZ3o83vGWp6lwR6Qv8HpgK\ndPYKrf8AfvdSsqYu3gZ08tXuwQlZPF4BvuG5JeKxH/Bfr1vU8VjPEnZLTQBWeiIC7r09EfXe2qnq\nTABVfVlVz8QVsqtx7zEWHwHH+r6/g2vhTajlOeLZ+1dcbb23quYCs6n6W23D9/6899o5znVrfbZD\ntKnuE1TXA/+kqpWwFSdaYVvbebZuiT7m0cc7Vtt7P5z/0x1AiOouvFj/i/1x8R7DhwlGyyVVRDJ8\nWwruB3WVVzsVEWknIueISA7QDvdD2wEgIpNxLYyko6obcG6QO0UkTUTGUFWgxOIJXEH3jIgcLyIB\nz699q4iEXSnLgMtEJCgi46ly19TGPODrwNVUtS4A/oJreXzDu16GiBSISC8RyRORCV5BV4ZzbcRz\n/ywAhotIhvfcu3Gxot+JyEQRyfGeZSju71EbObhWWamIjMa50MI8DZwrIqd4PcruIv5vOe6z1XF/\ncP8rlcCRCeQFwLvueCDsPpoLTBaRoV4s7W7gXU9Y5gPHishlIpIiIhcDA4B/1PHevwB6ec9+SHju\n0mdx/4tZXqvlO1HP0BMX71l8qNdv7ZhgtFzmAwd8252quhTXI+W3OPfIWlxPEzxf7f/gar1f4AK0\nbzWivZNwQeBwD6wncQVBDTxf9xm4WuUCXG+W93AumXe9bNfhRGe3d+3/q3mlGtfdhnv+k737h9M3\n4VoBt+IKyU3ANNzvIwDcgKsNf4kTpqvjXP8LYCG+FoWq/rd3/k249/4FrjPCzbieS/G4BrhLRIqB\nO3CxhfA1VwDX4kRvG+5vvTmOTbU9W614LsQZwFueO+ukOFkvFm8cBq7X0Vs4oURVX8HFWJ7xbD0K\nuMQ7tgvXq+8nuP+Lm3A92XZS+3tfiBOkz0VkZ13PEYOpuIB4uAfdXKr/L14G/Mn7PzR8iKotoGQ0\nPiLyJLBaVX/W1LY0JF4Ppj8Bo9V+XC0CEbkH6Kaq4bEXHwKnqur2Jjat2WGCYTQKIjIKV1P8DOcW\n+j9cv/5/N6lhRpvDc0OlActxvffm48YT1dlKbes02Wheo83RDec77oxzn1xtYmE0ETk4N1QPnIvw\nf0hsrEybx1oYhmEYRkJY0NswDMNIiFblkurSpYvm5+c32v327dtHu3Z19Y5snpjtTYPZ3jSY7fF5\n//33d6pqQtO5tyrByM/PZ+nSpY12v6KiIgoKChrtfg2J2d40mO1Ng9keHxGJHm0fF3NJGYZhGAlh\ngmEYhmEkRNIEQ0QeE7e62H/iHBcReUBE1orIRyIy3HdsvIis8Y7ZyleGYRjNgGTGMB7HTVHx5zjH\nzwKO8bYTcfP7n+hNP/wQcCauv/4SEXnBm9rCMNok5eXlbN68mdLS0rozJ4nc3FxWrVrVZPc/HMx2\nyMjIoFevXqSmptb7GkkTDFV93ZvzPh4TgD970ycsFpEO4hbzyQfWquo6ABGZ5+U1wTDaLJs3byYn\nJ4f8/HwkOUuB10lxcTE5OTl1Z2yGtHXbVZVdu3axefNm+vXrV+/rNGUvqZ5Un4d+s5cWK/3EeBcR\nkSm4hYPIy8ujqKiowQ2NR0lJSaPeryEx25uG+tqem5tL586dKSk5nEUID4+KigqKi4vrztgMMdsh\nLS2N3bt3H9Zvp8V3q1XVR4BHAEaOHKmN2XXOuuo1DW3R9lWrVtG+ffuGN+gQaOu19KaiIW3PyMhg\n2LBh9T6/KQVjC9UXLunlpaXGSTcMwzCakKbsVvsCbilH8ebZ3+OtV7AEOEZE+nkLpFxC7es/G4aR\nZHbt2sXYsWMZOnQo3bp1o2fPngwdOpShQ4dy8ODBhK4xefJk1qxZU2uehx56iDlz5jSEyUYSSFoL\nQ0TmAgW4NY03Az/DtR5Q1dm4KYXPxi3ysx+Y7B0LichU4GUgiFtA/lAWfzcMY84cuO022LgR+vSB\nGTNg0qR6X65z58689dZb5OTkcOedd5Kdnc2NN95YLY+qoqoEArHroX/84x/rvM+1115bbxuTSV3P\n1lZI2tOr6qWq2l1VU1W1l6r+QVVne2KBOq5V1aNUdbC3Wlz43Pmqeqx3bEaybDSMVsmcOTBlCmzY\nAKruc8oUl97ArF27lgEDBjBp0iQGDhzItm3bmDJlCiNHjmTgwIHcddddkbynnHIKy5YtIxQK0aFD\nB6ZPn86QIUMYM2YM27e7tYpuv/127r///kj+6dOnM3r0aI477jjeftstULhv3z4uuugiBgwYwMSJ\nExk5ciTLli2rYdu0adMYMGAAJ5xwAnfccQcAn3/+ORMmTOCEE05gyJAhvPuuW8Dxv//7vxk0aBCD\nBg3iwQcfjPts//znPxkzZgzDhw/n4osvZt++fQ3+TpszLT7obRhtjuuvhxgFZITFi6EsanXR/fvh\n+9+H3/8+9jlDh4JXUB8qq1ev5s9//jMjR44EYObMmXTq1IlQKERhYSETJ05kwIAB1c7Zs2cPp512\nGjNnzuSGG27gscceY/r0mmN0VZX33nuPF154gbvuuouXXnqJBx98kG7duvHMM8/w4YcfMnz48Brn\nffHFF8yfP58VK1YgImza5DpeXnvttZx55plMnTqVUCjE/v37effdd5kzZw5LliwhFAoxevRoCgoK\nyMzMrPZs27dvZ+bMmbz66qtkZWUxY8YMZs2axa233lqv99YSadvtK8NojUSLRV3ph8lRRx0VEQuA\nuXPnMnz4cIYPH86qVatYubLmEKrMzEzOOussAEaMGMH69etjXvvCCy+skefNN9/kkksuAWDIkCEM\nHDiwxnmdOnUiEAhw5ZVX8txzz0Vmey0qKuIHP/gBACkpKbRv354333yTiy66iMzMTHJycvjmN7/J\nG2+8UePZ3n77bVauXMnJJ5/M0KFDmTNnTly7WyvWwjCMlkZdLYH8fOeGiqZvX0jC+BX/1NuffPIJ\ns2bN4r333qNDhw5cfvnlMUenp6WlRfaDwSChUCjmtdPT0+vME4vU1FSWLl3KggUL+Nvf/saDDz7I\nwoULAQ5p4KP/2VSV8ePH88QTTyR8fmvDWhiG0dqYMQOysqqnZWW59CSzd+9ecnJyaN++Pdu2bePl\nl19u8HuMHTuWp556CoDly5fHbMEUFxezd+9ezj33XO677z4++ugjAAoLC5k9ezbgBsTt3buXcePG\n8dxzz3HgwAFKSkp4/vnnGTduXI1rnnzyybz22musW7cOcLGUTz75pMGfrzljLQzDaG2Ee0M1YC+p\nRBk+fDgDBgzg+OOPp2/fvowdO7bB7/HDH/6Q73znOwwYMCCy5ebmVsuzZ88eLrzwQsrKyqisrOTu\nu+8G4Le//S1XXnklDz/8MCkpKTz88MOMHj2aSy+9lFGjRgFw9dVXM3jwYNauXVvtmnl5efzhD3/g\n4osvjnQlvvvuuznmmGMa/BmbLeHuYq1hGzFihDYmixYtatT7NSRme9NQX9tXrlzZsIbUg7179za1\nCaqqWl5ergcOHFBV1Y8//ljz8/O1vLy81nOai+31oSFtj/V/BCzVBMtYa2EYhtGiKCkp4fTTTycU\nCqGqkdaCkXzsLRuG0aLo0KED77//flOb0SaxoLdhGIaRECYYhmEYRkKYYBiGYRgJYYJhGIZhJIQJ\nhmEYCfHFF19wySWXcNRRRzFixAjOPvtsPv7446Y2Kyb5+fns3LkTcAPuYvG9732Pp59+utbrPP74\n42zdujXy/Yorrog5ULCtYIJhGK2QOcvnkH9/PoGfB8i/P585yw9vplpV5bLLLqOgoIBPP/2U999/\nn1/96ld88cUX1fIdyvQdjUV4ltv6EC0Yjz76aI2JFJsDjfXeTTAMo5UxZ/kcpvx9Chv2bEBRNuzZ\nwJS/Tzks0Vi0aBGpqalcddVVkbQhQ4Ywbtw4ioqKGDduHOeff36kMP3Nb34TmS48PF35vn37OOec\ncxgyZAiDBg3iySefBGD69OmRacij19gAmD17NtOmTYt8f/zxx5k6dSoA3/zmNxkxYgQDBw7kkUce\niWl7dnY24ERv6tSpHHfccZxxxhmRKdUB7rrrLkaNGsWgQYOYMmUKqsrTTz/N0qVLmTRpEkOHDuXA\ngQMUFBSwdKlbiWHu3LkMHjyYQYMGcfPNN1e732233caQIUM46aSTaogqwGuvvRZZgGrYsGGRNbvv\nueceBg8ezJAhQyKz93700UecdNJJnHDCCVxwwQV89dVXABQUFHD99dczcuRIZs2axY4dO7jooosY\nNWoUo0aN4q233or/B60viY7wawmbjfROHLO9aWiIkd7X/fM6Pe2Pp8Xd0n+RrtxJjS39F+lxz7nu\nn9fVev9Zs2bpNddcE/eZsrKydN26daqqunTpUh00aJCWlJRocXGxDhgwQD/44AN9+umn9Yorroic\nt3v3bt25c6cee+yxWllZqaqqX331VY3rb9++XY866qjI9/Hjx+sbb7yhqqq7du1SVdX9+/frwIED\ndefOnaqq2rdvX92xY4eqqrZr10737t2rzzzzjJ5xxhkaCoV0y5Ytmpubq3/729+qXUdV9fLLL9cX\nXnhBVVVPO+00XbJkSeRY+PuWLVu0d+/eun37di0vL9fCwkJ97rnnVFUViJw/bdo0/cUvflHjmc49\n91x98803VVW1uLhYy8vLdf78+TpmzBjdt29fNZsGDhyoRUVFqqr605/+VK+77rqILVdffXXkmpde\nemnkvWzYsEGPP/74Gvc93JHe1sIwjFZGWUXsaczjpTcEo0ePpl+/foCbfvyCCy6gXbt2ZGdnc+GF\nF/LGG28wePBgFixYwM0338wbb7xBbm4uubm5ZGRk8P3vf59nn32WrOhJE4GuXbty5JFHsnjxYnbt\n2sXq1asjc1Q98MADkZr8pk2bap0M8PXXX+fSSy8lGAzSo0cPvva1r0WOLVq0iBNPPJHBgwezcOFC\nVqyofZHPJUuWUFBQQNeuXUlJSWHSpEm8/vrrgJuJ99xzzwXiT90+duxYbrjhBh544AF2795NSkoK\nr7zyCpMnT468g06dOrFnz57I2iEA3/3udyP3Abj44osj+6+88gpTp05l6NChnH/++ezdu5eSkpJa\nn+NQsZHehtHCuH987dOb59+fz4Y9Nac375vbl6LvFdXrngMHDoy4kGLhnwY8HsceeywffPAB8+fP\n5/bbb+f000/njjvu4L333uPVV1/l6aef5re//S0LFixgxIgRAJx//vncddddXHLJJTz11FMcf/zx\nXHDBBYgIRUVFvPLKK7zzzjtkZWVRUFAQcyr1uigtLeWaa65h6dKl9O7dmzvvvLNe1wmTmpoamUI9\n3rTs06dP55xzzmH+/PmMHTu23rP6+t97ZWUlixcvJiMjo36GJ4C1MAyjlTHj9BlkpVavqWelZjHj\n9PpPb/61r32NsrKyanGCjz76KLLQkJ9x48bxf//3f+zfv599+/bx3HPPMW7cOLZu3UpWVhaXX345\n06ZN44MPPqCkpIQ9e/Zw9tlnc9999/Hhhx8SDAZZtmwZy5YtiyzxesEFF/D8888zd+7cyOJJe/bs\noWPHjmRlZbF69WoWL15c6zOceuqpPPnkk1RUVLBt2zYWLVoEEBGHLl26UFJSUq3nVE5OTiS+4Gf0\n6NG89tpr7Ny5k4qKCubOnRtpBSTCp59+yuDBg7n55psZNWoUq1ev5swzz+SPf/wj+/fvB+DLL78k\nNzeXDh06RN7zE088Efc+X//61yPLywIxl609XKyFYRitjEmD3TTmt716Gxv3bKRPbh9mnD4jkl4f\nRIS//vWv3H777dxzzz1kZGSQn5/P/fffz5YtW6rlHT58ON/73vcYPXo04LqiDhs2jJdffplp06YR\nCARITU3lf//3fykuLmbChAmUlpaiqvzmN7+Jef+OHTvSv39/Vq5cGbnu+PHjmT17Nv379+e4447j\npJNOqvUZLrjgAhYuXMiAAQPo06cPY8aMAdzcVFdeeSWDBg2iW7dukWnOwXW9veqqq8jMzOSdd96J\npHfv3p2ZM2dSWFiIqnLOOecwYcKEhN/n/fffz6JFiwgEAgwcOJCzzjqL9PR0li1bxsiRI0lLS+Ps\ns8/m7rvvZvbs2fzkJz9h//79HHnkkfzxj3+Mec0HHniAa6+9lhNOOIFQKMSpp54aWfujoRAX82gd\njBw5UsM9GBqDoqIiCgoKGu1+DYnZ3jTU1/ZVq1bRv3//hjfoECguLiYnJ6dJbagvZrsj1v+RiLyv\nqiPjnFINc0kZhmEYCWGCYRiGYSSECYZhtBBak/vYaHwa4v/HBMMwWgAZGRns2rXLRMOoF6rKrl27\nDrvLrfWSMowWQK9evdi8eTM7duxoMhtKS0uT2sc/mZjtrtLRq1evw7pGUgVDRMYDs4Ag8Kiqzow6\n3hF4DDgKKAX+n6r+xzu2HigGKoBQolF8w2iNpKamRkZSNxVFRUUMGzasSW2oL2Z7w5A0wRCRIPAQ\ncCawGVgiIi+oqn9u4FuBZap6gYgc7+U/3Xe8UFV3JstGwzAMI3GSGcMYDaxV1XWqehCYB0SPbBkA\nLARQ1dVAvojkJdEmwzAMo54kbeCeiEwExqvqFd73bwMnqupUX567gUxV/bGIjAbe9vK8LyKfAXtw\nLqmHVTXm3MUiMgWYApCXlzdi3rx5SXmeWJSUlESmTm5pmO1Ng9neNJjt8SksLEx44F5TB71nArNE\nZBmwHPg3TiAATlHVLSJyBLBARFar6uvRF/CE5BFwI70bcwRwWxxx3Bww25sGs71paE62J1MwtgC9\nfd97eWkRVHUvMBlA3PSOnwHrvGNbvM/tIvIczsVVQzAMwzCMxiGZMYwlwDEi0k9E0oBLgBf8GUSk\ng3cM4ArgdVXdKyLtRCTHy9MO+DrwnyTaahiGYdRB0loYqhoSkanAy7hutY+p6goRuco7PhvoD/xJ\nRBRYAXzfOz0PeM6bUz4F+KuqvpQsWw3DMIy6SWoMQ1XnA/Oj0mb79t8Bjo1x3jpgSDJtMwzDMA4N\nmxrEMAzDSAgTjDCVlU1tgWEYRrPGBAOgvBw2boQDB5raEsMwjGaLCUaY0lInGnv3NrUlhmEYzRIT\njDlz4OijYcAAOP10ePhh2LkTbBppwzCMajT1SO+mZc4cmDIF9u9337dsgZ/9DETgsssgLw+Cwaa1\n0TAMo5nQtlsYt91WJRZhDhyA+++Hfftg0yYX3zAMwzDauGBs3Bg7fetWaNfO9ZzasMGC4YZhGLR1\nwejTJ3Z6djZUVEBGBqSmWjDcMAyDti4YM2ZAVlb1tGAQiovh8svhyy+dYGRluVaHBcMNw2jDtG3B\nmDQJHnnEtTREoGdPF7+4915491046yxYvtyJSE4O7NoF27a51odhGEYbo20LBjjRWLsWVq2Cd96B\nCy+ESy+F555zMYwJE+Cpp5yg5OS4ILkFww3DaIOYYIBzO/Xo4YLbpaUubcgQeOklGDkSfvxjuOUW\nOHjQuafCwXBzTxmG0YYwwQiTkwP5+RAIuC61qtC5M/z1r3D11fDnP8PEic4lFQ6GHzxowXDDMNoM\nJhh+0tJcPKNDBxf4rqiAlBS4/XaYPdu5rc46CxYvdoIRCFgw3DCMNoMJRjSBAHTt6gLgfhfVeefB\niy+6lsjFF8Mf/uBEwoLhhmG0EUww4hF2UQWDUFLixOHYY51onH463HEH/WfOdIJiwXDDMNoAJhi1\nkZYGvXtDx47ORRUKQfv28OijcNNNHFFU5Foe69dXD4bbyHDDMFohJhh1EXZR9e4NZWVODAIBuO46\nPpoxw7mizj4bXn3VRoYbhtGqMcFIlHbtnIsqLc21NlT5auRI+Oc/oVcv+O534b77nAurXTsLhhuG\n0eowwTgUUlOdOHTu7FoQqq5X1fPPuwF/994L/+//OUEJB8O3brVguGEYrQITjENFBLp0gb59nWAc\nOACZmTBrFvzyl7BokXNRrVnjROPAAQuGG4bRKjDBqC9ZWZCeXuWiApg8GZ5+2vWYOvdc1/KwYLhh\nGK0EE4zDpVcvFxQvLnatiFGj3JQigwbBNdfAXXe5wX8WDDcMo4VjgnG4iECnTi6WUV7uWhF5eW7C\nwsmT3Rrhl1wCe/ZYMNwwjBaNCUZDkZXlelFlZLjWRmqqi2nMmgX//jeMHw/Lllkw3DCMFktSBUNE\nxovIGhFZKyLTYxzvKCLPichHIvKeiAxK9NxmSUqKm/X2iCOqXFQTJ7pYRkoKXHSRm8zQguGGYbRA\nkiYYIhIEHgLOAgYAl4rIgKhstwLLVPUE4DvArEM4t3ki4kaG9+3rRobv3+/iGfPnw8knw003wbRp\nbvCfBcMNw2hBJLOFMRpYq6rrVPUgMA+YEJVnALAQQFVXA/kikpfguc2bzEwnGpmZLtDdoYObIv1H\nP3KtjIsucq6p1FQnGhYMNwyjmZNMwegJbPJ93+yl+fkQuBBAREYDfYFeCZ7b/Am7qPLy3ASGFRVw\n881uptu1a11c4733IDvbguGGYTR7RJNUQInIRGC8ql7hff82cKKqTvXlaY9zQw0DlgPHA1cCR9d1\nru8aU4ApAHl5eSPmzZuXlOeJRUlJCdnZ2YllVnXxClUIBMjctIlBP/85WZs3s+7732fTxImRY6Sm\nJtdwDtH2ZobZ3jSY7U1Dsm0vLCx8X1VHJpRZVZOyAWOAl33fbwFuqSW/AOuB9od6bngbMWKENiaL\nFi06tBNCIdWtW1VXrVLdtEl1zRrVc85RBdVzz1X9+GPVTz5R/ewz1YMHk2FyhEO2vRlhtjcNZnvT\nkGzbgaWaYLmeTJfUEuAYEeknImnAJcAL/gwi0sE7BnAF8Lqq7k3k3BZJMAjdukH37m4Z2LQ0N07j\n9ttdUPzcc93stxYMNwyjGZI0wVDVEDAVeBlYBTylqitE5CoRucrL1h/4j4iswfWIuq62c5Nla6Mi\nArm5LiBeWelE4eqrXSB8xw445xx4/XULhhuG0exISebFVXU+MD8qbbZv/x3g2ETPbVVkZDjR2L7d\njQIfO9Zz/UcXAAAgAElEQVRNKXLllW6E+HXXwY9/7ILhBw+6GXJFmtpqwzDaMDbSuykJBp17Kuyi\n6toVnnvOTSUya5YTjlDI9Z6ykeGGYTQxJhjNgdxcN60IOFG491645x54803notq40UaGG4bR5Jhg\nNBfS090Ehu3bu2lFLr0UnnnGuaMmTHAr+1kw3DCMJsQEozkRDLpBfj16VE0p8tJLMGyYGyE+Y4bL\nZ8FwwzCaABOM5kj79s5FJeKmFpk7F6ZMgcceg0mTXLzDRoYbhtHImGA0V8Iuqtxc54K6/Xb43e9g\n+XIX11izxoLhhmE0KiYYzZlAwLmoevZ0ovGNb8Df/+5aHd/6Fjz7rHNdWTDcMIxGwASjJZCT41xU\ngQD07g0vvginngq33Qa33upEw4LhhmEkGROMlkJamnNRdezohOMPf4Cf/ASefhouvhg+/9yC4YZh\nJBUTjJZEIOAG9/XsCWVlcM018PjjbpzGeefB++9bMNwwjKRhgtESCbuogkEYM8a5qLp3h29/G/70\nJzcnlQXDDcNoYEwwWippaS6e0bEjdOniAuATJsDMmXDDDW6Oqk2b3MA/wzCMBsAEoyUTdlH17u1a\nG7/+Ndx5JyxY4HpRrVljwXDDMBoME4zWQLt2zkWVluYmLpw3z82Ae9FF8OqrFgw3DKNBMMFoLaSm\nupZG585uSpF//AOOO86ttfHggy4wvmOHBcMNw6g3CQuGiJwiIpO9/a4i0i95Zhn1QsTFM/r0ccLx\nxBMuEP673znhWLvWguGGYdSbhARDRH4G3IxbWxsgFfhLsowyDpOsLLc4U06OG9x3772wZImLayxZ\n4oLh1tIwDOMQSbSFcQFwPrAPQFW3AjnJMspoAFJToVcvFxQ/5xw3wA9cjOOpp1zvKQuGG4ZxCCS6\nROtBVVURUQARaZdEm4yGQgQ6dXLLwaakuNX8brgBbr6ZY845x43dyM93s+MahmHUQaItjKdE5GGg\ng4hcCbwC/D55ZhkNSlaWE4bu3WH2bLjmGnq++KJbAvbf/7ZguGEYCZGQYKjqvcDTwDPAccAdqvpg\nMg0zGpiUFDelSPfu8MMfsuL22904jYkT3SJNFgw3DKMO6hQMEQmKyCJVXaCq01T1RlVd0BjGGQ1M\n2EXVty87TjkF/vY3546aPNn1pNq40UaGG4YRlzoFQ1UrgEoRyW0Ee4zGIDPTLdB0wgkuAH766XD3\n3XDddbBqlQXDDcOISaJB7xJguYgswOspBaCqP0qKVUbj0KOHi2/cd5+b9fbee+GTT+D++92khhYM\nNwzDR6KC8ay3Ga0JETd5YWYmXHUV9O/velH913/BPfe4qUW6dHH5DMNo8yQkGKr6JxFJA471ktao\nqq0J2lrIyHAD/b7xDRfXuP56t9bGihVw002uJRIMNrWVhmE0MYmO9C4APgEeAn4HfCwipyZw3ngR\nWSMia0VkeozjuSLydxH5UERWhKce8Y6tF5HlIrJMRJYm/ERG/QgGXQ+qkSNhzhz45jfht7+F737X\nCYcFww2jzZOoS+p/gK+r6hoAETkWmAuMiHeCiARxAnMmsBlYIiIvqOpKX7ZrgZWqep6IdAXWiMgc\nVQ2XToWquvPQHsmoNyLQoYNrcfz61y4oPmOGW83voYdccDwzs6mtNAyjiUh04F5qWCwAVPVj3HxS\ntTEaWKuq6zwBmAdMiMqjQI6ICJANfAmEErTJSBYZGW6g3w9+4FbwKy11cY3f/Q4efdQdCwTc55w5\nTWysYRiNRaItjKUi8ihVEw5OAupyE/UENvm+bwZOjMrzW+AFIDw31cWqWukdU+AVEakAHlbVRxK0\n1WgIgkHo1s3NQ9W7twuG33ijSw8P8NuwAaZMcfuTJjWdrYZhNAqiCUwJISLpOPfRKV7SG8DvVLWs\nlnMmAuNV9Qrv+7eBE1V1alSescANwFHAAmCIqu4VkZ6qukVEjvDSf6iqr8e4zxRgCkBeXt6IefPm\nJfDYDUNJSQnZ2dmNdr+G5JBsV0X272fst75FSowxGqV5eSy2954QZnvTYLbHp7Cw8H1VHZlQZlWt\ncwPaAUHf9yCQVcc5Y4CXfd9vAW6JyvMiMM73fSEwOsa17gRurMvOESNGaGOyaNGiRr1fQ3LItodC\nqiKqbtap6puIanGxy9MItKn33oww25uGZNsOLNUEdEBVE45hvAr4o52ZuAkIa2MJcIyI9PO65F6C\ncz/52QicDiAiebh5qtaJSDsRyfHS2wFfB/6ToK1GMggG3cJMsVCFwkK46y744AMoKbF5qQyjFZKo\nYGSoakn4i7efVdsJqhoCpgIvA6uAp1R1hYhcJSJXedl+AZwsIstxonSzul5RecCbIvIh8B7woqq+\ndCgPZiSBGTPcyHA/6ekwfjwUFzvBGDnS9abyi0fI+jEYRmsg0aD3PhEZrqofAIjISKDOCYdUdT4w\nPypttm9/K671EH3eOmBIgrYZjUU4sH3bbW6iwt694ac/hTPPhLIytwTsggUwf74TjF/8AkaNgrPO\nggkT4JhjqtbmMAyjxZHoL/d64G8istX73h24ODkmGc2aSZNi94gqL4e8PBgwwE0z8umnTjxefBF+\n/vMq8Rg/3onHUUe51oqJh2G0GGr9tYrIKGCTqi4RkeOBHwAXAi8BnzWCfUZLITUVcnPdVl7uuuQO\nGODGcsQSj9Gjq8TjyCNNPAyjBVBXDONhIDzqegxwK2709leAjYswYhMWj/x8JwYnn+ymTv/HP9w2\ndapb5e/OO2HECCccd9/tVv/bu9diHobRTKmrShdU1S+9/YuBR1T1GeAZEVmWXNOMVkFamts6dnTz\nUR1xhJsV9+qrXczjX/9yLY+f/czFPU480QnIueea28owmhl1CoaIpHg9nk7HGyCX4LmGUR2/eJSV\nVcU8rrnGrcOxYIFrgdxxh3NdnXSSm0H3vPPMbWUYzYC6fn1zgddEZCeuV9QbACJyNLAnybYZrZn0\ndLeFxeOII2DgQLj2WrfWeLR4jBlTJR6VlS5OklrXdGaGYTQktQqGqs4QkVdxvaL+5Y0KBBf7+GGy\njTPaCH7xOHgQunaFQYOceHz8cZXb6qc/hTvv5IShQ+GCC5zbql8/N4OuiYdhJJ062/equjhG2sfJ\nMcdo04jUbHmExWPq1EjLI/PZZ+H2213QfMyYqphH377ObWXiYRhJwRzCRvNExA3yy8iATp2ceHTp\nAoMG8e6551JQVuZaHv/4hxtI+LOfmXgYRpIxwTCaP37x6NzZjTIfOdK1PH74Q9fyePnlKvHwtzzO\nOcfEwzAaCBMMo2Uh4rYuXZx4lJa6z4ED4Uc/gtWrq8Tj1ltdy+Pkk930JGedZeJhGIeBCYbRchFx\nAe/MTCcgpaXOfTVwoBsouGpVlXhMn+6C5mPHupZHWDwyM11XX8Mw6sQEw2gd+MWja9cq8Rg0CK6/\nHlaurIp5FBW57rph8Rg/3sTDMBLABMNofcRqeXTsCIMHO/FYsaJKPBYtci2PU06pEo8+fUw8DCMG\nJhhG6yYQcDGLrKyqlkeHDlXisXJlldtq4cLq4vGNb0CvXtCunYmHYWCCYbQl/OJxxBFVLY8TToAf\n/9i1PF5+2Q0SfPVVN9bDxMMwIphgGG2TaPE4cMC1PIYMgRtugP/8p6Z4jBvnxOPrXzfxMNokJhiG\nEQi4wr9dOzdP1YEDbnr2IUPgxhth+XJ46SW3kuArr7iR6KeeWiUePXuaeBhtAhMMw/DjF4+KCue2\nat++uniEWx4LFjjxOO00Jx5nnOFaHllZLt0wWhkmGIYRj2CwungcOODEY+hQJx4ffVQlHv/6lxuJ\n7hePnj3hhRfc4MGNG6FPH464/HIoKGjqJzOMemGCYRiJEAxCdrbbwuKRk+PEY9o0Jx5ht9XLLzvx\nOPZYN3iwvNxdY8MGjrv3Xpf+7W+77r+G0YIwwTCMQ8UvHqGQc1vl5MCwYXDTTfDhh048nnjCxUT8\np5aVue68WVlusGD37k5c0tPddVNS3Gcw2EQPZxjxMcEwjMMhJaW6eOzf71xYw4bBn/8c+5yvvoJv\nfcvtt2vn4h7hrXdv99mnj1tlsEMHJyapqdUFxVonRhNggmEYDUVKiotxtG/vxKNXL9i0qWa+I46A\ne+5xxzZscJ8bN8LbbztXl5+uXZ2I9OxZJSa9e0N+vhOVcO+ssJCkpLjAvWEkARMMw0gGKSnwq1/B\nlCmu1eFRkZ5O8JZb3DxW4QUsVV2LIRCA3bthyxa3hcVkwwZYtswF1/0urtRUJyTRLZQ+feCoo5ww\nZWQ4W/yuLmudGPXEBMMwksWkSe7zttsivaTWXH45A66/3qVXVLiWSEWF28rK3BxWnTvDgAFOHPyF\ne2UlfPGFE5PNm6u3UF5+2bm6/OTkVLVKwmISbp0cdZQ7Hh07sdaJUQtJFQwRGQ/MAoLAo6o6M+p4\nLvAXoI9ny72q+sdEzjWMFsGkSVXCAWwvKmJA+Et0cDsnp2pftUpIQiG3HTxYJQKhUFW+8Boh+/bB\ntm1OTDZvdiK1cSOsWwevveYEKYwI5OXVjJ3k57t10vv0ca0Tf+zEaPMk7b9ARILAQ8CZwGZgiYi8\noKorfdmuBVaq6nki0hVYIyJzgIoEzjWM1otIlSsp1iDAsKCEWyihkBOEzp3huOOqBMXPrl2wdWtV\n6yQsKO++C88/X+UiA3fPcNykZ0/o04cuaWkuxnLUUS62kppaPXZirq5WTzKrDaOBtaq6DkBE5gET\nAH+hr0COiAiQDXwJhIATEzjXMNoufkGJRWVl9RZKebmb7qRnTzdqPRwLCbdQysvh88+r4idhMdm4\nEf79b9i7l0H+63fsWDN2kp/venb16+d6jUXHTowWTzIFoyfg7yKyGScEfn4LvABsBXKAi1W1UkQS\nOdcwjHgEAm6LtxRtZWX1+El5uVtw6uij3X5FRfUWQ0kJS995h5GBQPUWyurVbn6t8ODE8L27d6/Z\nTTg/H445Bnr0qOrZFd1NeM6cajEfZsyo5tIzmpamdkx+A1gGfA04ClggIm8cygVEZAowBSAvL4+i\noqKGtjEuJSUljXq/hsRsbxpalO3+XlyqlPTpQ1F6umtF+KmoIH3XLjK++ILMzz8n4/PPydy2jYzP\nPydj4ULSv/yyevaMDA5060aptx3o1o3S7t3J3LiRfn/5ixvcCLBhAxXf/z5rVq5k+5lnHtajtKj3\nHkVzsj2ZgrEF6O373stL8zMZmKmqCqwVkc+A4xM8FwBVfQR4BGDkyJFa0Ijz9BQVFdGY92tIzPam\noVXYrlq9hRKOnxw86DZ/a0PVHdu61bm6tm4luHEj2Zs2kb1xo5vMcd++uPcMlpUx4L77GLBpk3Nz\n5eS4cS65udW3jh3dlpNTFU8JBCKfRW+9RcG4cVXpLYjm9D+TTMFYAhwjIv1whf0lwGVReTYCpwNv\niEgecBywDtidwLmGYTQFIrXHJWL18Ore3a2vfvBg9YC8qht7snUrXHhh7OsdOOAmcSwurjHVSg38\n07bk5LgtO5v+4GyIJTodOrgtN9e55dq3d668KNGp8dkGSZpgqGpIRKYCL+O6xj6mqitE5Crv+Gzg\nF8DjIrIcEOBmVd0JEOvcZNlqGEYDkkgPL3/8JC/PxTd69nStkGh69HBrr4fXKikpqdr273dCEv5e\nXOy2vXur9nfsoP2uXW7wY3Fx7B5k0fa3a1dNcCKffiGKbumEhadjR/c9PT35otPIMZ+kxjBUdT4w\nPypttm9/K/D1RM81DKMVIOJq8NEB+XvuqTEynqws+OUvnZhUVla5wmJ9VlS4z3DPL9/nu+vXU5Cf\n765ZWurcYH7h8W9hofGLz1dfuUGSYXHyj2mJR1ZWjZZOtf3s7Pii06mT+8zIqBLKaLGZOxd+8IOq\n97Vhg3t/kDTRaOqgt2EYhiPGyPh61ZjDouH/3LrV9dYKu8v83Y79WzjdPyYlFgcPOuHYt696Cycs\nOOH06NbOtm1VaaWldT9LejonZ2U5MYkWnpdeqi6u4L7fdpsJhmEYbYCokfH1Iuzq8cdYwm6mRPF6\nhkVaNbG+J9LaqY3y8rpbOiUl7Ny4kR4pKVVCs3On+4zXWWDjxsSf8xAxwTAMw4gmPN3K4cQZwiIT\n3drxf4aFJZbweLGejz/7jB79+tW8fmGhazlF06dP/W2uAxMMwzCMZBAWHTi8ke5bt7rpWKIF55e/\nhGuvrT4lflaWc+MlibbZN8wwDKMlEZ6vKy3N9b7KzITJk+H3v3crN4q4z0ceabm9pAzDMIwk0hAx\nn0PAWhiGYRhGQphgGIZhGAlhgmEYhmEkhAmGYRiGkRAmGIZhGEZCmGAYhmEYCWGCYRiGYSSECYZh\nGIaRECYYhmEYRkKYYBiGYRgJYYJhGIZhJIQJhmEYhpEQJhiGYRhGQphgGIZhGAlhgmEYhmEkhAmG\nYRiGkRAmGIZhGEZCmGAYhmEYCWFLtBqGYbQQVBVFq+2ruu+pwdSk398EwzAMI0HiFdjx0sKFeXi/\nUiup1EqAyH54C58TnXaw4iBrv1xLZWUliLuHICCAAgIBCZDfIZ+UQHKLdBMMwzBaDPUtsCu1kuKy\n4loL7FhpkfOprLXARp0oiEitaYIAICK17osIKZISSctMyXTXiUNJWUkDveHaSapgiMh4YBYQBB5V\n1ZlRx6cBk3y29Ae6quqXIrIeKAYqgJCqjkymrYZhNAzhmnR0wR0rLVQZqlFI+9MOpcAG4hbi5RXl\nbCvZVu8CO5zWVDTlvf0kTTBEJAg8BJwJbAaWiMgLqroynEdVfw382st/HvBjVf3Sd5lCVd2ZLBsN\noy1TV2HuT6vUSiq0gh37dlQr3Cu0gorKCpenjkI9VpogBMT1vQkXzAEJNHiBHQgEyE7LPux31tZJ\nZgtjNLBWVdcBiMg8YAKwMk7+S4G5SbTHMFoksdws8Qr42mrr/kI+XLDXVpj70wQhVBlib9neagW4\nIKQEUppFLdxIPhJu8jX4hUUmAuNV9Qrv+7eBE1V1aoy8WbhWyNHhFoaIfAbswbmkHlbVR+LcZwow\nBSAvL2/EvHnzkvE4MSkpKSE7u2XWWsz2xsPvX99Xso922e2q0tV3POq7Pw1IyAVDVHktUQkRUagH\npftKyWiXUb+Tm5jWbntlZSXpKen1un5hYeH7ibr8m0vQ+zzgrSh31CmqukVEjgAWiMhqVX09+kRP\nSB4BGDlypBYUFDSKwQBFRUU05v0aErP90IhVgw+7Y0KVoWpbOK3GNVDWf7ieXoN7RWrt0bV1Ec8l\nE5XWHFixZAUDRw1sajPqRWu3vaSshCM7Hdmie0ltAXr7vvfy0mJxCVHuKFXd4n1uF5HncC6uGoJh\nGPUhlvumUisJVbhCv7yyvEoAtCLSiyYWAQlU29JS0siQ2DXCgATITm85rSPD8JNMwVgCHCMi/XBC\ncQlwWXQmEckFTgMu96W1AwKqWuztfx24K4m2Gi2YeP77sA8/XPiXV5THrf2HidTwvc+UQAppktZs\navmG4efZVc8y882ZbC3eSu/c3tx9+t1MGjyp7hPrSdIEQ1VDIjIVeBnXrfYxVV0hIld5x2d7WS8A\n/qWq+3yn5wHPeT/SFOCvqvpSsmw1mhfxCn+/+2fL3i2UV5QT0lCdtf9wz5tw7T+ddBMAo8Xz7Kpn\nuWnBTRwIHQBg456NTPn7FICkiUZSHV6qOh+YH5U2O+r748DjUWnrgCHJtM1oHOqq/fu38sryiDBA\njICtV+uv1ErKK8sJBAJkSEakW6bR8vHXmHvk9GD6KdO5sP+FTW1WnVRqpavAVIY4WHGQ8spyyivK\nI/sHKw5SXlEeSY9Oi7dfXlHOti3baL+vfY3jL336EqWh0mp27C/fz22v3tYyBcNonYQHXIV9+9G1\n/1jBX3/Pn3DtPrr2nxpIjbiDakNESAumJe8BjSYhusa8pXgL0xZM40DoAOOPGl+t8A27GGMVyOH9\nUGWIg5Vuf9PmTSzUhVXn+PLGK+Sj92s7Xpub83BJlVTSt6eTGkglLZhGSiCF1GBqDbEIs3HPxqTZ\nYoJhJERFZQVlFWWUHCyhuKyYUGUIEYn01Y/2/dcV/G0rRNeYL+9xOQNp/r11KrWSslAZZRVlkc+N\n+zei25XSUGkk7WDFQcpCZZRWlFbP7+2Xhkpdnhjp/muXhcrYUrylhnuxNFTKTQtu4qYFNx3+Q33m\nPlICKS42FUwjNZBKajA1sp8WTCM1mOrSA6lkpWa54wEv3bcfPiclmFIjLXo/VlptecN2BCXIyqUr\nY/aSGv370WwprtmPqE9un8N/V3EwwTBiEp70rDRUyp6yPZSWl6IoKYEU0lPSyZTMpjax2ROrxnz/\nJ/fTa1WvWt0s4RZcdIHq/6xW4PoK71jp/gI90cK7vLI8tnHvJ/78acE00oPppKekV/vMSMkgPZhO\ndlo2nTM7R9KfWfVM3Gv9svCXcQvsRArnT5d9ygmjTiA1mNpqXJjTT5le7f8LICs1ixmnz0jaPU0w\njAixWhEBCZAaTLWuoLUQqgyxu3Q3u0t389WBr/iq9Cu+OvAVP3/t59V+zABllWXc+K8beXzZ4zUK\nb38tvbZAfiIIQnpKOhnBDFcgRxXa6SnpdMrsRHpKuivYfemRc8L5vf3t67dz9HFH17hOWADCaeHr\nHWrBvHjz4pg15p45PZk8bPJhvY9tKdvqPbCtuRKudLSKXlJG88daEdVRVfaV76tW6Ps/owXhq1K3\n7S3be0j3KasoIys1i46ZHasXvlEFdHRBXK3gj5HuL+jD03U0JCv2r2Dg0clzp8WqMWemZDL9lOlJ\nu2dL58L+F3Jh/wtbxcA9oxkSbkWEKkOs+2pdq21FlFeU113Y+wr98PG4rhggJy2Hjpkd6Zjhtn4d\n+9ExoyMdMjpUpfs+L3ryIraWbK1xnZ45PZk3sfGmsGkpRNeYW1IvqbaCCUYrx9+K2Fu2lwPlB1CU\nCq1oEa0IVaX4YHG1Qn759uUs/mBxTUHwfS85GH99gLRgWqTQ75jZkaM7Hh230A9/5qbnHvKKZreM\nu6VGjTk9kG415loI15iN5okJRiskkVhEuCfToXI4/eTLQmV1u3qiju8u3U2FVtS82Br30SG9Ax0y\nO9AxoyNdMrtwdKejYxf6vv2s1KxGGbgXq8Z8eY/LrUA0WiwmGK2AeK2Iho5FxOr1c+O/bmTF9hX0\n79q/TjHYX74/7rUzUjJcLd8r2I/rfFyNQj/cCtj1yS5Gjx5NbnouwUCwQZ4tWUTXmFcsWdGE1hjG\n4WGC0ULxtyJKykrcyOckxiK+KPmCOxbdUbPXT0UZs9+vGrwfkAC56bmRQr5bdjf6d+lfo9CPrv1n\npiYuaiu2rKBTZqcGezbDMBLDBKOFoKqUV5ZzoPxAzFZEQw+QK68o5/1t77Pos0UsWr+IFTvi14wF\n4Y3Jb9AxsyPt09u3mn7uhmFUxwSjGdPYrYitxVtZ9NkiitYX8cbGNyg+WExKIIVRPUZxyym38Id/\n/4Ht+7bXOK9HTg/6dezX4PYYRmMRXkiu2uJVGrWQ1SGkRacnek54N7wWObjFkUrKSqqlRVZDBLe2\nSiNNpmmC0Yxo7FZEWaiMJVuXRERi9a7VAHTP7s75x51PYX4hY/uMpX16e8AJg/WTb13UVlBGp4Vj\nZYmcW+0etRWS/uxSdQ1/YRgvrdr5MdJiFbrV8vruHQhUtYoDVK0xHkmLWnfcn+bfj5XmXwSrrnP8\n9wzfZ3NwM71ye1VLi84nIkkfgwEmGE1OY7ciNu3ZxML1C/n7ir/z4eIP2V++n9RAKif2OpGfDvwp\nhfmFHNv52Jg1FusnXzf+2XkVb+1tLw3cHE3hLr+JFoyHkxarQE60oIwu6AQhNVDVtbi2wi9WIRmz\nMI1RQEbbkEiaPz1W2taUrRzd+ehaz2+uBCRAVmpWU5sBmGA0Oo3diigNlfLu5ndZuH4hReuLWPvl\nWgDy0vOYOGCia0X0Hku7tHYJXa8t9JOvrdCPrk1Xm4Jd3I87KEGCgSApkhKZ6C7cjXljYCPds7tX\nnZJAwZhooZpo4VnfQvLT4Kf0bN+zXuc2Byy2dviYYDQCjd2K+Oyrz1i03gWr3970NqWhUtKD6Yzp\nNYbLT7icwvxCSteWMmj0oAa/d3PBX8BHCn/VyPdwnug1N+oq9P2Fv39mXv863LURlCA56TnJemzD\nSComGEmgsVsRB8oP8PamtyMisX73egDyO+Rz2aDLKOxXyJheY6p1XV0hzX88QLxCP65bhyq/dbgQ\nD0rQTUEdSKkSAa/Qj1XgJ7Ieh2G0VUwwGojGbEWoKp9+9akTiM8WsXjzYsoqyshIyWBs77FcMewK\nCvILmkXPJX+tPl5Nv3onEa3m+w4QIBioKvTDtfzu2d2t0DeMRsYEo56EC709pXsirQjEuRyS0YrY\nd3Afb216i4WfuVjEpr2bADi609F8Z8h3KMwv5MReJ5KRkvwFiyoqKzhYcbCafz9WLR+c3zxcs08N\npFar5YdnVI1V4NdW6JtbxzCaBhOMQyC6FXEwdJDt+7YnrRWxZtcaitYXsfCzhby35T3KK8tpl9qO\nU/qcwjWjrqEwv5Deub0b9L7xbAkva6koqYFUctJzIrX++hT6hmG0PEwwaiFWLMLfiggEAgn3LkqE\nvWV7eXPjm5HR1dtKtgFwfOfjuWK4czON7jm6UdazDq9zXFFZgYhEVkfLTM085FlbDcNoHZhgRNHY\nsYgVO1ZQtL6IRZ8tYum2pYQqQ+Sk5TCu7zhuyL+BgvwCeuT0aND7xrMlvE6GqpIWTKNTZicyUzLr\ntXqaYRitDxMMXGG5t2xvo8Qidpfu5vUNr7NovRtdHZ5qY2DXgVw18ioK8wsZ0X1Eo9TiyyvKI7EI\nwbUictJzyEjJaJRRo4ZhtCysVMC5X7aVbCMjJaPBWxGVWsnyL5ZHurx+sO0DKrWSDukdODX/VAry\nCyjoW0Bedl6D3jeeLWWhMioqKyI9lLpkdSEzNZP0YLrFGwzDqBUTDI+ABBosNvDlgS95bf1rLFy/\nkER9ohwAAAo1SURBVNfWv8auA7sAGJI3hB+N/hEF/QoY1m1Yo9TiI8FqVQKBADlpOWSnZbM1uJW+\nHfom/f6GYbQeTDAagIrKCpZ9vszFItYvYtnny1CUjhkdKcgvoDC/kNPyT6NLVpek2xJuRYQqQwhC\nRmoGR7Q7goyUDNKCadaKMAyj3iRVMERkPDALCAKPqurMqOPTgEk+W/oDXVX1y7rObWp27NvBgi8W\n8NCLD/HahtfYXbobQRjWfRg/GfMTCvILOCHvhKSvCBfuyXUwdDDS5bV9envapbUjPZje7FekMwyj\n5ZA0wRCRIPAQcCawGVgiIi+o6spwHlX9NfBrL/95wI89sajz3MYmVBnig20fREZXL9++HHAxgDOO\nPIOv5X+NcX3HNcpKcOGeXBWVFQQkQGZKJp2yO5GRmtEoXW4Nw2ibJLOFMRpYq6rrAERkHjABiFfo\nXwrMree59WbO8jnc+uqtbNqzqcZ03Z+XfB4ZOPfGxjfYW7aXoAQZ0WMEN4+9mT77+3B+wflJ73Ia\nHjgXXosgNZhKh/QOrhVhXV4Nw2gkJNaCJw1yYZGJwHhVvcL7/m3gRFWdGiNvFq4lcbTXwjiUc6cA\nU7yvxwFrEjYyi07k0hfwl7iVFLOZA+yu8/xKOhHgy4Tvd6iIzy6lkkoqvPm1G+KP1gXY2QDXaQrM\n9qbBbG8akm17X1XtmkjG5hL0Pg94S1UPufBV1UeARxrepLoRkaUa0pFNce/DRUSWqprtjY3Z3jSY\n7Q1DMn0ZWwD/REe9vLRYXEKVO+pQzzUMwzAagWQKxhLgGBHpJyJpOFF4ITqTiOQCpwHPH+q5hmEY\nRuORNJeUqoZEZCrwMq5r7GOqukJErvKOz/ayXgD8S1X31XVusmw9DJrEFdZAmO1Ng9neNJjtDUDS\ngt6GYRhG68L6YxqGYRgJYYJhGIZhJIQJRhQisl5ElovIMhFZ6qV1EpEFIvKJ99nRl/8WEVkrImtE\n5Bu+9BHeddaKyAOShEmcROQxEdkuIv/xpTWYrSKSLiJPeunvikh+km2/U0S2eO9+mYic3Uxt7y0i\ni0RkpYisEJHrvPRm/+5rsb3Zv3sRyRCR90TkQ8/2n3vpLeG9x7O92b/3aqiqbb4NWA90iUr7b2C6\ntz8duMfbHwB8CKQD/YBPgaB37D3gJECAfwJnJcHWU4HhwH+SYStwDTDb278EeDLJtt8J3Bgjb3Oz\nvTsw3NvPAT72bGz2774W25v9u/fuk+3tpwLvevdvCe89nu3N/r37N2thJMYE4E/e/p+Ab/rS56lq\nmap+BqwFRotId6C9qi5W99f7s++cBkNVX4caI80b0lb/tZ4GTg/XZpJkezyam+3bVPUDb78YWAX0\npAW8+1psj0dzsl1VtcT7muptSst47/Fsj0ezsd2PCUZNFHhFRN4XN+0IQJ6qbvP2PwfCqx31BDb5\nzt3spfX09qPTG4OGtDVyjqqGgD1A5+SYHeGHIvKROJdV2LXQbG33mv3DcDXGFvXuo2yHFvDuRSQo\nIsuA7cACVW0x7z2O7dAC3nsYE4yanKKqQ4GzgGtF5FT/QU/VW0Rf5JZkq8f/AkcCQ4FtwP80rTm1\nIyLZwDPA9aq613+sub/7GLa3iHevqhXe77MXrsY9KOp4s33vcWxvEe89jAlGFKq6xfvcDjyHmzn3\nC68piPe53csebwqTLd5+dHpj0JC2Rs4RkRQgF9iVLMNV9QvvR1UJ/B737pul7SKSiitw56jqs15y\ni3j3sWxvSe/es3c3sAgYTwt577Fsb2nv3QTDh4i0E5Gc8D7wdeA/uGlJvutl+y5V05i8AFzi9U7o\nBxwDvOc1j/eKyEmeD/E7VJ/6JJk0pK3+a00EFno1uKQQ/tF7XIB7983Odu9efwBWqepvfIea/buP\nZ3tLePci0lVEOnj7mbj1clbTMt57TNtbwnuvxqFGyVvzhmsafuhtK4DbvPTOwKvAJ8ArQCffObfh\nejCswdcTChjp/fE/hf/f3r2FxlHFcRz//jTWS0p8EFqCCFoaNIm9UJM8lEgr4vVN6gUtPtiAVVSq\nBUF8KJUGrHitF9CIiBqxaq0XhIrQh0JspdYYkprqg4gPakWRgkpSi/n7cM62221ix7Blc/l9YMnM\n5szMfye788+Z2fkfniffVV/leN8idWOPkM5ldlUzVuAs4F3SBbe9wIJTHPsbwBAwSHrzN07R2DtJ\npz0GgYH8uH467Pv/iH3K73tgMfBVjnE/sKHan88axD7l93v5w6VBzMysEJ+SMjOzQpwwzMysECcM\nMzMrxAnDzMwKccIwM7NCnDBsWpF0Xlllz4M6vtLnnILreFXSxSdpc4+k1dWJemqQ1Cdpaa3jsOnL\nX6u1aUvSRuDPiHii4nmR3ttjNQlsipLUB9wbEQO1jsWmJ/cwbEaQtFBpjIc3STddNkrqkbRPafyB\nDWVt+yQtlVQn6ZCkzUrjFOyRNC+36ZZ0f1n7zUrjGXwraXl+vl7Se3m72/K2TvgPXlK7pF1KBS13\nSJov6Yw835nbPK5jYyQ8IukLSfslvZgTYCmOp/J2hiW1SXpfaRyIjWX74WtJWyUdkPROvrO4Mqbr\n8uvtVxpDob4sjmGlYniPVfWPZNOeE4bNJJcAT0dES6SaYA9FRBuwBLhKUss4y5wL7IqIJcAeYM0E\n61ZEdAAPAqXkcx9wMCJagE2kyq/HLySdCWwBVkXEZUAvsCkijgB3AD2SrgauALrzYlsioh1YlOO7\ntmyVI/k1vQJ8ANyV291ZKj1BGkvhmYhoBkaBtRUxzSONG3FlRCwj3WW8TtJ80l3frRGxGHh0gn1h\ns5QThs0k30XEvrL5WyX1A/1AM+lAWmkkInbk6S+BCydY9/Zx2nQCWwEiolROplIz0EoqmT9AOlBf\nkJcZzMt/CKzJSQTSOAZ7SSVqVuTlSz7KP4eAoUjF60ZJA3+VitJ9HxGf5+neHGe55aR9sTvHtDq/\npt+BMeBlSTcAf02wL2yWqqt1AGZVdPQAJ6kJWAd0RMQhSb2kWjuV/i6b/oeJPxOHC7QZj4DBiLh8\ngt9fShq3oHQq7BxSfaBlEfGjpO6KuEtxjJVNl+ZLcVVemKycF/BJRNx+QrBSG6kw3k3A3aQCnGaA\nexg2czUAf5AqezYC15yk/WR8BtwMIGkR4/dghoHzJXXkdnMktebpW4C5wErgBUkNwNmkg/9vSpWT\nV00irosktefp24C+it/vBlZIWpDjqJfUlLfXEBEfAw8wzik2m93cw7CZqp90sP4G+IF0cK+254DX\nJQ3nbQ2TegtHRcRhSTcCz+aEcDrwpKRfSdc9VkbET5JeIl1/6ZL0Wl7XzxwbDe//OACszxfgh4Ce\niph+kdQFvF32VeSHgRFge77uchqwfhLbthnMX6s1mySlQWrqImI0nwL7FGiKNDxmrWJaCGyLNLKb\nWVW5h2E2eXOBnTlxCFhby2Rhdqq5h2FmZoX4oreZmRXihGFmZoU4YZiZWSFOGGZmVogThpmZFfIv\n7MWawg6IlQoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105a55f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# строим кривые обучения для градиентного бустинга\n",
    "X = data_new_mean.drop('labels', axis =1)\n",
    "y = data['labels']\n",
    "\n",
    "title = \"Learning Curves (Gradient Boosting)\"\n",
    "estimator = GradientBoostingClassifier(random_state=42)\n",
    "cv = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=42)\n",
    "plot_learning_curve(estimator, title, X, y, ylim=(0.7, 1.01), cv=cv, n_jobs=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графиков, качество модели на кросс-валидации растет логарифмически с увеличением количества обучающих объектов примерно до 0.72-0.73 (после 20 тыс. объектов), а затем значительное увеличение качества не происходит. Таким образом, для построения модели достаточно около 20 тыс. объектов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "доля оттока =  0.0744\n",
      "доля не оттока =  0.9256\n"
     ]
    }
   ],
   "source": [
    "churn = data[data['labels'] == 1] # формируем класс отток\n",
    "non_churn = data[data['labels'] == -1]   # формируем класс не отток\n",
    "\n",
    "churn_share = len(churn)/float(data.shape[0])\n",
    "non_churn_share = 1-churn_share\n",
    "print (\"доля оттока = \", churn_share)\n",
    "print (\"доля не оттока = \", non_churn_share)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Т.к. в классификаторе GradientBoostingClassifier нет параметра для выбора соотношения весов (параметр class_weight), то попробуем применить другой классификатор, например, RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.596698455429\n",
      "ROC_AUC на тесте= 0.500535678692\n"
     ]
    }
   ],
   "source": [
    "# модель без балансировки классов\n",
    "rf_classifier = RandomForestClassifier(random_state = 42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(rf_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,rf_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.601115027836\n",
      "ROC_AUC на тесте= 0.500671155571\n"
     ]
    }
   ],
   "source": [
    "# автоматическая балансировка весов\n",
    "rf_classifier = RandomForestClassifier(random_state = 42, class_weight='balanced')\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(rf_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,rf_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.599730494368\n",
      "ROC_AUC на тесте= 0.503319962129\n"
     ]
    }
   ],
   "source": [
    "# уменьшаем класс неотток (-1) до 60%, а класс отток (1) увеличиваем до 40%\n",
    "rf_classifier = RandomForestClassifier(random_state = 42, class_weight={-1:0.6, 1:0.4})\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(rf_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,rf_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.604482978754\n",
      "ROC_AUC на тесте= 0.500312998306\n"
     ]
    }
   ],
   "source": [
    "# уменьшаем класс неотток (-1) до 30%, а класс отток (1) увеличиваем до 70%\n",
    "rf_classifier = RandomForestClassifier(random_state = 42, class_weight={-1:0.3, 1:0.7})\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(rf_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,rf_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.60217511593\n",
      "ROC_AUC на тесте= 0.501209948675\n"
     ]
    }
   ],
   "source": [
    "# уменьшаем класс неотток (-1) до 5%, а класс отток (1) увеличиваем до 95%\n",
    "rf_classifier = RandomForestClassifier(random_state = 42, class_weight={-1:0.05, 1:0.95})\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(rf_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,rf_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Балансировка весов через параметр модели позволяет улучшить качество классификации в случае, когда веса превалирующего класса уменьшаются до 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "доля оттока =  0.5\n",
      "доля не оттока =  0.5\n"
     ]
    }
   ],
   "source": [
    "# формируем набор сэмплированных данных \n",
    "np.random.seed(42)\n",
    "sample_size = len(churn)\n",
    "non_churn_indices = non_churn.index\n",
    "random_indices = np.random.choice(non_churn_indices, sample_size, replace=False) # 1й вариант выбора индексов\n",
    "non_churn_sample = data_new_mean.loc[random_indices]\n",
    "churn_sample = data_new_mean[data_new_mean['labels']==1]\n",
    "# формируем выборку со сбалансированными классами \n",
    "merged_sample = pd.concat([churn_sample, non_churn_sample], ignore_index=True)\n",
    "\n",
    "#проверяем баланс классов после undersampling'a\n",
    "churn_undsmpl = merged_sample[merged_sample['labels'] == 1]\n",
    "non_churn_undsmpl = merged_sample[merged_sample['labels'] == -1]\n",
    "churn_undsmpl_share = len(churn_undsmpl)/float(merged_sample.shape[0])\n",
    "non_churn_undsmpl_share = 1-churn_undsmpl_share\n",
    "print (\"доля оттока = \", churn_undsmpl_share)\n",
    "print (\"доля не оттока = \", non_churn_undsmpl_share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "доля оттока =  0.3333333333333333\n",
      "доля не оттока =  0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "# 2й вариант выбора индексов (меняем количество отфильтрованных объектов)\n",
    "np.random.seed(42)\n",
    "random_indices = np.random.choice(non_churn_indices, int(len(churn)/0.5), replace=False)\n",
    "non_churn_sample_2 = data_new_mean.loc[random_indices]\n",
    "merged_sample_2 = pd.concat([churn_sample, non_churn_sample_2], ignore_index=True)\n",
    "\n",
    "churn_undsmpl_2 = merged_sample_2[merged_sample_2['labels'] == 1]\n",
    "non_churn_undsmpl_2 = merged_sample_2[merged_sample_2['labels'] == -1]\n",
    "churn_undsmpl_share_2 = len(churn_undsmpl_2)/float(merged_sample_2.shape[0])\n",
    "non_churn_undsmpl_share_2 = 1-churn_undsmpl_share_2\n",
    "print (\"доля оттока = \", churn_undsmpl_share_2)\n",
    "print (\"доля не оттока = \", non_churn_undsmpl_share_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "доля оттока =  0.3893249607535322\n",
      "доля не оттока =  0.6106750392464678\n"
     ]
    }
   ],
   "source": [
    "# 3й вариант (меняем принцип выбора объектов)\n",
    "np.random.seed(42)\n",
    "random_indices = [int(i) for i in np.random.uniform(0, 40000, 5000) if int(i) in non_churn_indices]\n",
    "non_churn_sample_3 = data_new_mean.loc[random_indices]\n",
    "merged_sample_3 = pd.concat([churn_sample, non_churn_sample_3], ignore_index=True)\n",
    "\n",
    "churn_undsmpl_3 = merged_sample_3[merged_sample_3['labels'] == 1]\n",
    "non_churn_undsmpl_3 = merged_sample_3[merged_sample_3['labels'] == -1]\n",
    "churn_undsmpl_share_3 = len(churn_undsmpl_3)/float(merged_sample_3.shape[0])\n",
    "non_churn_undsmpl_share_3 = 1-churn_undsmpl_share_3\n",
    "print (\"доля оттока = \", churn_undsmpl_share_3)\n",
    "print (\"доля не оттока = \", non_churn_undsmpl_share_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.723462871012\n",
      "ROC_AUC на тесте= 0.67392980183\n"
     ]
    }
   ],
   "source": [
    "# проверяем качество первой модели\n",
    "X = merged_sample.drop('labels', axis =1)\n",
    "y = merged_sample['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=42)\n",
    "# Градиентный бустинг \n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.718395047477\n",
      "ROC_AUC на тесте= 0.620118239091\n"
     ]
    }
   ],
   "source": [
    "# проверяем качество второй модели\n",
    "X = merged_sample_2.drop('labels', axis =1)\n",
    "y = merged_sample_2['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Градиентный бустинг \n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.729315857604\n",
      "ROC_AUC на тесте= 0.649092004326\n"
     ]
    }
   ],
   "source": [
    "# проверяем качество третьей модели\n",
    "X = merged_sample_3.drop('labels', axis =1)\n",
    "y = merged_sample_3['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Градиентный бустинг \n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты классификации меняются в зависимости от способов балансировки классов. Наилучший результат был получен в случае, когда индексы большего класса сэмплировались из равномерного распределения в количестве 4668 объектов. При этом, баланс классов оставался несколько смещен в сторону большего класса. При этом, наилучший результат на тестовой выборке показала балансировка классов, с равенством доли большего и меньшего классов (первый вариант)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Первый способ обработки пропущенных значений был - заполнение их средними по столбцам (работаем с вещественными и закодированными категориальными данными). Далее попробуем заполнить их 0 и медианами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.712237717463\n",
      "ROC_AUC на тесте= 0.507630306956\n"
     ]
    }
   ],
   "source": [
    "# замена пропущенных значений на средние по столбцам\n",
    "X = data_new_mean.drop('labels', axis =1)\n",
    "y = data['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.714789827253\n",
      "ROC_AUC на тесте= 0.507046354893\n"
     ]
    }
   ],
   "source": [
    "# замена пропущенных значений на 0\n",
    "data_zeros = pd.concat([num_features,encoding_cat_data], axis = 1).fillna(0)\n",
    "data_zeros['labels'] = data['labels']\n",
    "\n",
    "X = data_zeros.drop('labels', axis =1)\n",
    "y = data_zeros['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# замена пропущенных значений на медианы по столбцам\n",
    "data_median = data_new[data_new.columns[0]].fillna(data_new.median(axis=0)[0])\n",
    "for i in range(len(data_new.columns)-1):\n",
    "    data_median = np.vstack((data_median,data_new[data_new.columns[i+1]].fillna(data_new.median(axis=0)[i+1]))) \n",
    "data_new_median = pd.DataFrame(data_median.transpose(),columns=data_new.columns)\n",
    "data_new_median['labels'] = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.714789827253\n",
      "ROC_AUC на тесте= 0.507046354893\n"
     ]
    }
   ],
   "source": [
    "X = data_new_median.drop('labels', axis =1)\n",
    "y = data_new_median['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее оптимистичными по качеству на обучающих данных оказались стратегии заполнения пропущенных значений нулями и медианами. Однако, на тестовых данных лучший результат оказался при заполнении средними."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "В первом варианте категориальные данные кодировались заменой каждой категории числом входящих в неё объектов (пропущенные значения обрабатывались по той же стратегии, что и вещественные). Далее попробуем другие принципы кодирования: \n",
    "2. Заменим пропущенные категориальные значения на 'Nan', приведем к строковому типу, отбросим признаки, у которых более 1000 уникальных значений и применим DictVectorizer\n",
    "3. Заменим пропущенные категориальные значения на 'Nan' и применим LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 1185)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2й вариант (с DictVectorizer) \n",
    "cat_features = data.iloc[:, 174:].fillna('NA').applymap(str)\n",
    "# список признаков, количество уникальных значений которых меньше 1000\n",
    "features_to_encode = []\n",
    "for f in cat_features.columns:\n",
    "    if len(np.unique(cat_features[f])) <1000:\n",
    "        features_to_encode.append(f)\n",
    "cat_features_to_encode = cat_features[features_to_encode].drop('labels', axis = 1)\n",
    "\n",
    "encoder = DV(sparse = False)\n",
    "encoder.fit(cat_features_to_encode.T.to_dict().values())\n",
    "encoded_cat_features = encoder.transform(cat_features_to_encode.T.to_dict().values())\n",
    "\n",
    "num_features_mean = num_features[num_features.columns[0]].fillna(num_features.mean(axis=0)[0])\n",
    "for i in range(len(num_features.columns)-1):\n",
    "    num_features_mean = np.vstack((num_features_mean,num_features[num_features.columns[i+1]].fillna(num_features.mean(axis=0)[i+1])))\n",
    "num_features_new_mean = pd.DataFrame(num_features_mean.transpose(),columns=num_features.columns)\n",
    "\n",
    "data_new = pd.concat([num_features_new_mean,pd.DataFrame(encoded_cat_features)], axis = 1)\n",
    "data_new['labels'] = data['labels']\n",
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.707417510935\n",
      "ROC_AUC на тесте= 0.508304576938\n"
     ]
    }
   ],
   "source": [
    "X = data_new.drop('labels', axis =1)\n",
    "y = data_new['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 204)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3й вариант (LabelEncoder)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(np.unique(cat_features_to_encode.as_matrix()))\n",
    "encoded_cat_features = pd.DataFrame([encoder.transform(i) for i in cat_features_to_encode.values])\n",
    "\n",
    "\n",
    "num_features_mean = num_features[num_features.columns[0]].fillna(num_features.mean(axis=0)[0])\n",
    "for i in range(len(num_features.columns)-1):\n",
    "    num_features_mean = np.vstack((num_features_mean,num_features[num_features.columns[i+1]].fillna(num_features.mean(axis=0)[i+1])))\n",
    "num_features_new_mean = pd.DataFrame(num_features_mean.transpose(),columns=num_features.columns)\n",
    "\n",
    "data_new = pd.concat([num_features_new_mean,pd.DataFrame(encoded_cat_features)], axis = 1)\n",
    "data_new['labels'] = data['labels']\n",
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.693612418208\n",
      "ROC_AUC на тесте= 0.505071818318\n"
     ]
    }
   ],
   "source": [
    "X = data_new.drop('labels', axis =1)\n",
    "y = data_new['labels']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат по качеству на обучении и тесте показал первый вариант, когда категориальные данные кодировались заменой каждой категории числом входящих в неё объектов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.736774447657\n",
      "ROC_AUC на тесте= 0.508304576938\n"
     ]
    }
   ],
   "source": [
    "X = data_new_mean.drop('labels', axis =1)\n",
    "y = data['labels']\n",
    "\n",
    "# 1я стратегия: с применением метода опорных векторов\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.741693392652\n",
      "ROC_AUC на тесте= 0.506194563484\n"
     ]
    }
   ],
   "source": [
    "# 2я стратегия: применение решающего дерева для отбора признаков\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшей, из рассмотренных, оказалась стратегия отбора признаков на основе решающего дерева, т.к. это более сложная стратегия по сравнению с линейным методом опорных векторов и более подходящая для нашей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# выберем оптимальные стратегии обработки данных: \n",
    "1. Балансировка классов методом undersampling (с одинаковыми долями каждого класса)\n",
    "2. Заполнение пропущенных вещественных значений на средние по столбцам\n",
    "3. Обработка категориальных признаков DictVectorizer'ом\n",
    "4. Отбор признаков с использованием решающего дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# формируем набор сэмплированных данных \n",
    "np.random.seed(42)\n",
    "sample_size = len(churn)\n",
    "non_churn_indices = non_churn.index\n",
    "random_indices = np.random.choice(non_churn_indices, sample_size, replace=False)\n",
    "non_churn_sample = data.loc[random_indices]\n",
    "churn_sample = data[data['labels']==1]\n",
    "# формируем выборку со сбалансированными классами \n",
    "data_sample = pd.concat([churn_sample, non_churn_sample], ignore_index=True)\n",
    "# удаляем полностью пустые столбцы\n",
    "empty_cols = data_sample.columns[np.where(data_sample.count() == 0)]\n",
    "for cols in empty_cols:\n",
    "    data_sample.drop(cols, axis =1, inplace = True)\n",
    "# формируем вещественную часть и категориальную          \n",
    "cat_features = data_sample.iloc[:, 174:]\n",
    "num_features = data_sample.drop(cat_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# заменяем пропущенные вещественные значения на средние по столбцам\n",
    "num_features_mean = num_features[num_features.columns[0]].fillna(num_features.mean(axis=0)[0])\n",
    "for i in range(len(num_features.columns)-1):\n",
    "    num_features_mean = np.vstack((num_features_mean,num_features[num_features.columns[i+1]].fillna(num_features.mean(axis=0)[i+1]))) \n",
    "num_features_new_mean = pd.DataFrame(num_features_mean.transpose(),columns=num_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 1705)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# кодируем категориальные данные с использованием DictVectorizer\n",
    "cat_features = data_sample.iloc[:, 174:].fillna('NA').applymap(str)\n",
    "# список признаков, количество уникальных значений которых меньше 1000\n",
    "features_to_encode = []\n",
    "for f in cat_features.columns:\n",
    "    if len(np.unique(cat_features[f])) <1000:\n",
    "        features_to_encode.append(f)\n",
    "cat_features_to_encode = cat_features[features_to_encode].drop('labels', axis = 1)\n",
    "\n",
    "encoder = DV(sparse = False)\n",
    "encoder.fit(cat_features_to_encode.T.to_dict().values())\n",
    "encoded_cat_features = encoder.transform(cat_features_to_encode.T.to_dict().values())\n",
    "\n",
    "# объединяем обработанные данные\n",
    "data_result = pd.concat([num_features_new_mean,pd.DataFrame(encoded_cat_features)], axis = 1)\n",
    "data_result['labels'] = data_sample['labels']\n",
    "data_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5952, 363)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проводим отбор признаков с решающим деревом\n",
    "X = data_result.drop('labels', axis = 1)\n",
    "y = data_sample['labels']\n",
    "clf = ExtraTreesClassifier(random_state=42)\n",
    "clf = clf.fit(X, y)\n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42)\n",
    "cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[ 1  1 ..., -1  1], n_folds=10, shuffle=True, random_state=42),\n",
       "       error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=42,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 2, 3, 4, 5], 'n_estimators': array([20, 30, 40, 50, 60, 70, 80])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# делаем подбор параметров\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "param_grid = {'n_estimators':np.arange(20,81,10),\n",
    "              'max_depth': [1,2,3,4,5]}\n",
    "grid_cv = GridSearchCV(gb_classifier, param_grid, cv = cv)\n",
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 80}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC с подбором параметров на обучении= 0.777061306688\n",
      "ROC_AUC с подбором параметров на тесте= 0.74401999779\n"
     ]
    }
   ],
   "source": [
    "# итоговые оценки по roc_auc \n",
    "print (\"ROC_AUC с подбором параметров на обучении=\", roc_auc_score(y_train,grid_cv.predict_proba(X_train)[:,1]))\n",
    "print (\"ROC_AUC с подбором параметров на тесте=\", roc_auc_score(y_test,grid_cv.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на обучении= 0.730598280143\n",
      "ROC_AUC на тесте= 0.673271913701\n"
     ]
    }
   ],
   "source": [
    "gb_classifier = GradientBoostingClassifier(n_estimators=80, max_depth = 2, random_state=42)\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "# оценка по основной метрике - ROC_AUC \n",
    "print (\"ROC_AUC на обучении=\", cross_val_score(gb_classifier, X_train, y_train, scoring = 'roc_auc', cv=cv, n_jobs=-1).mean())\n",
    "print (\"ROC_AUC на тесте=\", roc_auc_score(y_test,gb_classifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После подбора параметров качество (как на обучении, так и на тесте) выросло. Оптимальными параметрами оказались 80 деревьев с глубиной 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Важность признака</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.219183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.074742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.059034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.056785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.048698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.040057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.035289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.033637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.027847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.026135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0.020423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.018273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.016934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.015088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.014924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.014483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.014222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.013677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.011499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.009974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.009685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.009311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.009068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.008863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.008834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.008721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.008150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.007776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Важность признака\n",
       "31            0.219183\n",
       "46            0.074742\n",
       "17            0.059034\n",
       "305           0.056785\n",
       "16            0.048698\n",
       "307           0.040057\n",
       "12            0.035289\n",
       "26            0.033637\n",
       "20            0.027847\n",
       "9             0.026135\n",
       "3             0.022529\n",
       "360           0.020423\n",
       "23            0.018273\n",
       "281           0.016934\n",
       "41            0.015088\n",
       "359           0.014924\n",
       "284           0.014483\n",
       "40            0.014222\n",
       "254           0.013677\n",
       "277           0.011499\n",
       "13            0.009974\n",
       "45            0.009685\n",
       "30            0.009311\n",
       "285           0.009068\n",
       "34            0.008863\n",
       "200           0.008834\n",
       "135           0.008721\n",
       "11            0.008251\n",
       "278           0.008150\n",
       "84            0.007776\n",
       "..                 ...\n",
       "127           0.000000\n",
       "138           0.000000\n",
       "126           0.000000\n",
       "125           0.000000\n",
       "123           0.000000\n",
       "122           0.000000\n",
       "121           0.000000\n",
       "120           0.000000\n",
       "119           0.000000\n",
       "137           0.000000\n",
       "139           0.000000\n",
       "157           0.000000\n",
       "149           0.000000\n",
       "156           0.000000\n",
       "155           0.000000\n",
       "154           0.000000\n",
       "153           0.000000\n",
       "152           0.000000\n",
       "151           0.000000\n",
       "150           0.000000\n",
       "148           0.000000\n",
       "140           0.000000\n",
       "147           0.000000\n",
       "146           0.000000\n",
       "145           0.000000\n",
       "144           0.000000\n",
       "143           0.000000\n",
       "142           0.000000\n",
       "141           0.000000\n",
       "362           0.000000\n",
       "\n",
       "[363 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оценим важность признаков с помощью метода feature_importances_ нашего классификатора \n",
    "importances = gb_classifier.feature_importances_\n",
    "feature_importances = pd.DataFrame({'Важность признака': importances})\n",
    "feature_importances.sort_values('Важность признака', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Важные признаки:  Index(['Var19', 'Var21', 'Var37', 'Var57', 131, 133], dtype='object')\n",
      "Неважные признаки:  Index(['Var2', 'Var3', 'Var7', 'Var12', 'Var17'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# наиболее важные признаки для модели (важность более 0.04)\n",
    "print (\"Важные признаки: \", X.columns[feature_importances[feature_importances['Важность признака']>0.04].index])\n",
    "\n",
    "# наименее важные признаки для модели (важность 0, ограничимся 5 признаками, т.к. их много)\n",
    "print (\"Неважные признаки: \", X.columns[feature_importances[feature_importances['Важность признака']==0].index][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[ 1  1 ..., -1  1], n_folds=10, shuffle=True, random_state=42),\n",
       "       error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=42,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 2, 3, 4, 5], 'n_estimators': array([20, 30, 40, 50, 60, 70, 80])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сделаем отбор признаков (важность более 0)\n",
    "important_feature_indexes = feature_importances[feature_importances['Важность признака']>0].index\n",
    "X_important = X_new[:,important_feature_indexes]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_important, y, test_size=0.3, random_state=42)\n",
    "cv = StratifiedKFold(y_train, n_folds=10, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 30}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC с подбором параметров на обучении= 0.849149985892\n",
      "ROC_AUC с подбором параметров на тесте= 0.731469902874\n"
     ]
    }
   ],
   "source": [
    "# итоговые оценки по roc_auc \n",
    "print (\"ROC_AUC с подбором параметров на обучении=\", roc_auc_score(y_train,grid_cv.predict_proba(X_train)[:,1]))\n",
    "print (\"ROC_AUC с подбором параметров на тесте=\", roc_auc_score(y_test,grid_cv.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отбор признаков методом feature_importances и новый подбор параметров (оптимальные параметры: 30 деревьев с максимальной глубиной 5) классификатора позволяет еще сильнее улучшить качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Non_churn (-1)</th>\n",
       "      <th>Churn (1)</th>\n",
       "      <th>Test_labels</th>\n",
       "      <th>y_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.342375</td>\n",
       "      <td>0.657625</td>\n",
       "      <td>-1</td>\n",
       "      <td>4039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.497601</td>\n",
       "      <td>0.502399</td>\n",
       "      <td>-1</td>\n",
       "      <td>4247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.351790</td>\n",
       "      <td>0.648210</td>\n",
       "      <td>1</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.793192</td>\n",
       "      <td>0.206808</td>\n",
       "      <td>-1</td>\n",
       "      <td>4765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176305</td>\n",
       "      <td>0.823695</td>\n",
       "      <td>1</td>\n",
       "      <td>1374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.566571</td>\n",
       "      <td>0.433429</td>\n",
       "      <td>-1</td>\n",
       "      <td>5192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.580050</td>\n",
       "      <td>0.419950</td>\n",
       "      <td>1</td>\n",
       "      <td>1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.410533</td>\n",
       "      <td>0.589467</td>\n",
       "      <td>-1</td>\n",
       "      <td>3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.498746</td>\n",
       "      <td>0.501254</td>\n",
       "      <td>-1</td>\n",
       "      <td>4801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.229175</td>\n",
       "      <td>0.770825</td>\n",
       "      <td>1</td>\n",
       "      <td>2899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Non_churn (-1)  Churn (1)  Test_labels  y_index\n",
       "0        0.342375   0.657625           -1     4039\n",
       "1        0.497601   0.502399           -1     4247\n",
       "2        0.351790   0.648210            1     1966\n",
       "3        0.793192   0.206808           -1     4765\n",
       "4        0.176305   0.823695            1     1374\n",
       "5        0.566571   0.433429           -1     5192\n",
       "6        0.580050   0.419950            1     1894\n",
       "7        0.410533   0.589467           -1     3960\n",
       "8        0.498746   0.501254           -1     4801\n",
       "9        0.229175   0.770825            1     2899"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# формируем таблицу с предсказаниями вероятностей классов и реальными (тестовыми) классами\n",
    "pred_proba = pd.DataFrame(grid_cv.predict_proba(X_test), columns = ['Non_churn (-1)', 'Churn (1)'])\n",
    "errors_table = pd.concat([pred_proba,pd.DataFrame(y_test.values, columns = ['Test_labels'])], axis=1)\n",
    "errors_table['y_index'] = y_test.index\n",
    "errors_table.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество ошибок на классе отток 312 , что составляет 33.8 % от общего количество объектоов данного класса\n",
      "Количество ошибок на классе неотток 612 , что составляет 71.0 % от общего количество объектоов данного класса\n"
     ]
    }
   ],
   "source": [
    "# список ошибок по классу \"1\" (т.е. класс 1, но предсказывается класс -1 с вероятностью > 0.5)\n",
    "churn_lab = errors_table[errors_table['Test_labels'] == 1]\n",
    "churn_er_ind = churn_lab[churn_lab['Non_churn (-1)'] >=0.5].index\n",
    "# список объектов, на которых получаются ошибки по 1 классу\n",
    "index_churn_error = errors_table.loc[churn_er_ind]['y_index'].values\n",
    "\n",
    "# список ошибок по классу \"-1\" (т.е. класс -1, но предсказывается класс 1 с вероятностью > 0.5)\n",
    "non_churn_lab = errors_table[errors_table['Test_labels'] == -1]\n",
    "non_churn_er_ind = churn_lab[churn_lab['Churn (1)'] >=0.5].index\n",
    "# список объектов, на которых получаются ошибки по -1 классу\n",
    "index_non_churn_error = errors_table.loc[non_churn_er_ind]['y_index'].values\n",
    "\n",
    "print (\"Количество ошибок на классе отток\", len(index_churn_error), \", что составляет\", round(len(index_churn_error)*100/len(churn_lab), 1),\"% от общего количество объектоов данного класса\")\n",
    "print (\"Количество ошибок на классе неотток\", len(index_non_churn_error), \", что составляет\", round(len(index_non_churn_error)*100/len(non_churn_lab), 1),\"% от общего количество объектоов данного класса\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как себя ведут отобранные признаки (4 наиболее важных): ['Var19', 'Var21', 'Var37', 'Var57']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var19</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var37</th>\n",
       "      <th>Var57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>68.980769</td>\n",
       "      <td>127.473929</td>\n",
       "      <td>4.505448</td>\n",
       "      <td>258.053665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>53.014343</td>\n",
       "      <td>435.201215</td>\n",
       "      <td>20.037931</td>\n",
       "      <td>46.792292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.617564</td>\n",
       "      <td>253.140675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>253.140675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>104.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>253.140675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>258.000000</td>\n",
       "      <td>5978.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>420.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Var19        Var21       Var37       Var57\n",
       "count  312.000000   312.000000  312.000000  312.000000\n",
       "mean    68.980769   127.473929    4.505448  258.053665\n",
       "std     53.014343   435.201215   20.037931   46.792292\n",
       "min      4.000000     0.000000  -30.000000  114.000000\n",
       "25%     28.000000     0.000000    1.617564  253.140675\n",
       "50%     55.000000    28.000000    4.000000  253.140675\n",
       "75%    104.500000    91.000000   10.000000  253.140675\n",
       "max    258.000000  5978.000000   64.000000  420.000000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим объекты, на которых возникает ошибка по классу отток\n",
    "X_test_frame = pd.DataFrame(X_test, index = y_test.index, columns = X.columns[feature_importances[feature_importances['Важность признака']>0].index])\n",
    "X_test_frame_churn = X_test_frame.loc[index_churn_error]\n",
    "X_to_analyse = X_test_frame_churn[['Var19', 'Var21', 'Var37', 'Var57']]\n",
    "X_to_analyse.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим уникальные значения данных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4.,    6.,    8.,   10.,   12.,   14.,   16.,   18.,   20.,\n",
       "         22.,   24.,   26.,   28.,   30.,   32.,   34.,   36.,   38.,\n",
       "         40.,   42.,   44.,   46.,   48.,   50.,   52.,   54.,   56.,\n",
       "         58.,   60.,   62.,   64.,   66.,   70.,   72.,   74.,   76.,\n",
       "         78.,   80.,   82.,   84.,   86.,   88.,   90.,   92.,   94.,\n",
       "         96.,   98.,  100.,  102.,  104.,  106.,  108.,  110.,  112.,\n",
       "        114.,  116.,  118.,  120.,  124.,  126.,  128.,  130.,  132.,\n",
       "        134.,  136.,  138.,  142.,  144.,  150.,  154.,  160.,  162.,\n",
       "        164.,  166.,  170.,  172.,  174.,  176.,  178.,  180.,  190.,\n",
       "        192.,  194.,  214.,  222.,  228.,  244.,  258.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_to_analyse['Var19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     7.        ,    14.        ,    21.        ,\n",
       "          28.        ,    35.        ,    42.        ,    49.        ,\n",
       "          56.        ,    63.        ,    70.        ,    77.        ,\n",
       "          80.99647234,    84.        ,    91.        ,    98.        ,\n",
       "         105.        ,   112.        ,   119.        ,   126.        ,\n",
       "         133.        ,   147.        ,   154.        ,   161.        ,\n",
       "         168.        ,   175.        ,   189.        ,   196.        ,\n",
       "         203.        ,   210.        ,   217.        ,   224.        ,\n",
       "         231.        ,   245.        ,   252.        ,   259.        ,\n",
       "         273.        ,   280.        ,   294.        ,   301.        ,\n",
       "         308.        ,   315.        ,   322.        ,   329.        ,\n",
       "         336.        ,   343.        ,   350.        ,   357.        ,\n",
       "         364.        ,   399.        ,   420.        ,   441.        ,\n",
       "         490.        ,   504.        ,   532.        ,   560.        ,\n",
       "         595.        ,   644.        ,   742.        ,   798.        ,\n",
       "         861.        ,   931.        ,   973.        ,  1190.        ,\n",
       "        4081.        ,  5978.        ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_to_analyse['Var21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-30.        , -28.        , -26.        , -24.        ,\n",
       "       -22.        , -20.        , -18.        , -16.        ,\n",
       "       -14.        , -12.        ,  -8.        ,  -6.        ,\n",
       "        -2.        ,   1.61756446,   4.        ,   6.        ,\n",
       "         8.        ,  10.        ,  12.        ,  14.        ,\n",
       "        16.        ,  18.        ,  20.        ,  22.        ,\n",
       "        24.        ,  26.        ,  28.        ,  30.        ,\n",
       "        32.        ,  34.        ,  36.        ,  38.        ,\n",
       "        40.        ,  42.        ,  44.        ,  46.        ,\n",
       "        48.        ,  54.        ,  56.        ,  58.        ,\n",
       "        60.        ,  62.        ,  64.        ])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_to_analyse['Var37'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 114.        ,  132.        ,  138.        ,  144.        ,\n",
       "        150.        ,  156.        ,  162.        ,  174.        ,\n",
       "        180.        ,  186.        ,  192.        ,  198.        ,\n",
       "        204.        ,  210.        ,  216.        ,  222.        ,\n",
       "        228.        ,  234.        ,  240.        ,  246.        ,\n",
       "        253.14067524,  258.        ,  264.        ,  270.        ,\n",
       "        276.        ,  282.        ,  288.        ,  294.        ,\n",
       "        300.        ,  306.        ,  312.        ,  318.        ,\n",
       "        324.        ,  330.        ,  348.        ,  354.        ,\n",
       "        360.        ,  366.        ,  372.        ,  378.        ,\n",
       "        390.        ,  396.        ,  402.        ,  408.        ,\n",
       "        414.        ,  420.        ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_to_analyse['Var57'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "66\n",
      "43\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "print (len(np.unique(X_to_analyse['Var19'])))\n",
    "print (len(np.unique(X_to_analyse['Var21'])))\n",
    "print (len(np.unique(X_to_analyse['Var37'])))\n",
    "print (len(np.unique(X_to_analyse['Var57'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Значения Var19 практически представляют собой арифметическую прогрессию с шагом 2\n",
    "2. Значения Var21 практически представляют собой арифметическую прогрессию с шагом 7\n",
    "3. Значения Var37 практически представляют собой арифметическую прогрессию с шагом 2, но с минимальным значением -30\n",
    "4. Значения Var57 практически представляют собой арифметическую прогрессию с шагом 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000000001BFEC438>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000026905278>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000000269C33C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000026C1FE48>]], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIsAAARuCAYAAABTBrdfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3X+wpXddJ/j3Z9KgLMMKGLyGELdxK6YG7TGjt4I7/tir\n+CMkjOAUxSQbhQg7La64WttTs82MO7JaVKVmJkOtgDDtkgKqYoAaxKTsFBhZzyK7MvwykATIEPAy\npAmJgBu8yKgNn/2jTz/evn1v39PnnnPP7e7Xq+rWfZ7v8+vzfHJueHjnec5T3R0AAAAASJK/s+gC\nAAAAANg7hEUAAAAADIRFAAAAAAyERQAAAAAMhEUAAAAADIRFAAAAAAyERQAAAAAMhEXAKarqnVX1\na5uMP7eqPl9V+6bY55Gqur+qvl5VN25Y9g1V9aqq+lxV/XlV/WZVPWYHpwAAwNisr+2q6juq6vaq\n+rOq+lJVvauqrli3/LvGY1+oqp7FOQC7T1gEbPSmJD9dVbVh/GeS3Nrdxyfd0bqLj48k+Z+SfHiT\n1Q4nWU7yXUm+I8n3JPmVsy0aAIBNzfra7olJ7khyRZKlJO9Pcvu61f4myduSvGQnRQOLJSwCNvrd\nJN+c5AdPDlTVk5I8J8mbq+raqvqTqvpyVX22ql6xbr39VdVV9ZKq+s9J/q8k6e7Xdve7k/yXTY73\nj5K8uru/1N1/luQ3krx4bmcHAHBhmem1XXe/v7vfML52+5skr0pyRVV9c5J09/3d/YYk9+3iOQIz\nJiwCTtHdX82J/xr0wnXDL0jyie7+SJKvjJc9Mcm1SX6+qp63YTf/fZK/l+Qnpiihkjytqr5pim0B\nAFhnF67tfijJ57v7i7OuHVgcYRGwmTcleX5VfeN4/oXjsXT3qLvv6e6vd/dHk9yWExcQ672iu78y\nvjjZzjuT/FJVPaWqvjXJ/zwe/692fhoAAGRO13ZV9bQkr03yv8y3fGC3CYuA03T3e5N8Icnzquq/\nTXJVkt9Okqp6ZlX94fhLDR9N8tIkF2/YxWfP4nCvTPInSe5O8v/mxK3Sf5Pk4Z2dBQAAyXyu7arq\nKUl+P8lvdvdtcz0BYNcJi4CtvDkn/qvTTyd5V3efDG9+Oye+1PCy7v6mJK/PiUfH1pv4zRfd/dXu\nfll3X9rd357ki0k+1N1f3/EZAABw0syu7cbfefT7Se7o7lfOtWpgIYRFwFbenORHk/zTjG9THntC\nki9193+pqquS/A/b7aiqHju+7bmSPKaqvrGq/s542aVV9dQ64fuS/G9JfnXWJwMAcIGbybVdVf3X\nSd6V5P/p7sObLK/xdd9jx/PfWFXfMKNzAHZJdU98AwBwgamqUZLvTvKt3f1X47HnJ7k5yZOT/N9J\nVpM8sbt/uqr2J/nTJI9Z/xrW8X42Pvv+w909qqofyomLl2/JiVucf627b53fWQEAXJhmcW1XVS9K\n8sYkf5lT7zh6Rnf/53XbrPeZ7t4/h1MC5kRYBAAAAMDAY2gAAAAADIRFAAAAAAyERQAAAAAMhEUA\nAAAADIRFAAAAAAz2LbqAzVx88cW9f//+qbb9yle+ksc//vGzLYgkejsv+jo/ejs/ejs/e623H/rQ\nh77Q3U9ZdB2cu3ZyXXcme+1vZa/Sp8no02T0aTL6tD09msw8+jTptd2eDIv279+fD37wg1NtOxqN\nsrKyMtuCSKK386Kv86O386O387PXeltVn1l0DZzbdnJddyZ77W9lr9KnyejTZPRpMvq0PT2azDz6\nNOm1ncfQAAAAABgIiwAAAAAYCIsAAAAAGAiLAAAAABgIiwAAAAAYCIsAAAAAGAiLAAAAABgIiwAA\nAAAYCIsAAAAAGAiLAAAAABgIiwAAAAAYCIsAAAAAGAiLAAAAABgIiwAAAAAYCIsAAAAAGAiLAAAA\nABgIiwAAAAAYbBsWVdVlVfWHVfWxqrqvqn5pPP7kqrqrqj45/v2kLba/uqrur6oHqurwrE8AAAAA\ngNmZ5M6i40kOdfczknxfkl+oqmckOZzk3d19eZJ3j+dPUVUXJXltkmcneUaS68fbAgAAALAHbRsW\ndfdD3f3h8fRfJPl4kkuTPDfJm8arvSnJ8zbZ/KokD3T3p7v7r5O8ZbwdAAAAAHvQvrNZuar2J/kH\nSf5jkqXufmi86PNJljbZ5NIkn103/2CSZ26x74NJDibJ0tJSRqPR2ZQ2WFtbm3rbve6eY4+eNnbg\n0m/ateOfz71dJH2dH72dH72dH72Fydxz7NHcePjoKWOrN127oGoA4PwycVhUVX83yduT/HJ3f7mq\nhmXd3VXVOymku48kOZIky8vLvbKyMtV+RqNRpt12r9t4QZQkqzes7Nrxz+feLpK+zo/ezo/ezo/e\nAgCwaBO9Da2qHpMTQdGt3f074+GHq+qS8fJLkjyyyabHkly2bv5p4zEAAAAA9qBJ3oZWSd6Q5OPd\n/e/WLbojyYvG0y9Kcvsmm38gyeVV9fSqemyS68bbAQAAALAHTXJn0fcn+ZkkP1JVd49/rklyU5If\nq6pPJvnR8Xyq6qlVdWeSdPfxJC9L8q6c+GLst3X3fXM4DwAAAABmYNvvLOru9yapLRY/a5P1P5fk\nmnXzdya5c9oCAQAAANg9E31nEQAAAAAXBmERAMAFqqpuqapHquredWNvXffVA6tVdfd4fH9VfXXd\nstcvrnIAYJ62fQwNAIDz1huTvCbJm08OdPc/OTldVTcneXTd+p/q7it3rToAYCGERQAAF6jufk9V\n7d9s2fiNuC9I8iO7WRMAsHjCIgAANvODSR7u7k+uG3v6+LG0R5P8Snf/0WYbVtXBJAeTZGlpKaPR\naObFLT0uOXTg+Clj8zjOuW5tbU1fJqBPk9GnyejT9vRoMovsk7AIAIDNXJ/ktnXzDyX5tu7+YlV9\nb5Lfrarv7O4vb9ywu48kOZIky8vLvbKyMvPiXn3r7bn5nlMvZVdvmP1xznWj0Sjz6P/5Rp8mo0+T\n0aft6dFkFtknX3ANAMApqmpfkn+c5K0nx7r7r7r7i+PpDyX5VJLvWEyFAMA8CYsAANjoR5N8orsf\nPDlQVU+pqovG09+e5PIkn15QfQDAHAmLAAAuUFV1W5I/TnJFVT1YVS8ZL7oupz6CliQ/lOSj4+8s\n+g9JXtrdX9q9agGA3eI7iwAALlDdff0W4zduMvb2JG+fd00AwOK5swgAAACAgbAIAAAAgIGwCAAA\nAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAA\ngIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACA\ngbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICB\nsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGw\nCAAAAICBsAgAAACAwb7tVqiqW5I8J8kj3f1d47G3JrlivMoTk/x/3X3lJtuuJvmLJF9Lcry7l2dU\nNwAAAABzsG1YlOSNSV6T5M0nB7r7n5ycrqqbkzx6hu1/uLu/MG2BAAAAAOyebcOi7n5PVe3fbFlV\nVZIXJPmR2ZYFAAAAwCJMcmfRmfxgkoe7+5NbLO8kf1BVX0vy77v7yFY7qqqDSQ4mydLSUkaj0VQF\nra2tTb3tXnfowPHTxnbzXM/n3i6Svs6P3s6P3s6P3gIAsGg7DYuuT3LbGZb/QHcfq6pvSXJXVX2i\nu9+z2YrjIOlIkiwvL/fKyspUBY1Go0y77V534+Gjp42t3rCya8c/n3u7SPo6P3o7P3o7P3oLAMCi\nTf02tKral+QfJ3nrVut097Hx70eSvCPJVdMeDwAAAID5mzosSvKjST7R3Q9utrCqHl9VTzg5neTH\nk9y7g+MBAAAAMGfbhkVVdVuSP05yRVU9WFUvGS+6LhseQauqp1bVnePZpSTvraqPJHl/kqPd/c7Z\nlQ4AAADArE3yNrTrtxi/cZOxzyW5Zjz96STfvcP6AAAAANhFO3kMDQAAAIDzjLAIAAAAgIGwCAAA\nAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCADgAlVVt1TVI1V177qxV1TV\nsaq6e/xzzbplL6+qB6rq/qr6icVUDQDMm7AIAODC9cYkV28y/qruvnL8c2eSVNUzklyX5DvH2/xm\nVV20a5UCALtGWAQAcIHq7vck+dKEqz83yVu6+6+6+0+TPJDkqrkVBwAszL5FFwAAwJ7zi1X1wiQf\nTHKou/88yaVJ3rdunQfHY6epqoNJDibJ0tJSRqPRzAtcelxy6MDxU8bmcZxz3dramr5MQJ8mo0+T\n0aft6dFkFtknYREAAOu9LsmvJ+nx75uTvPhsdtDdR5IcSZLl5eVeWVmZcYnJq2+9PTffc+ql7OoN\nsz/OuW40GmUe/T/f6NNk9Gky+rQ9PZrMIvvkMTQAAAbd/XB3f627v57kt/K3j5odS3LZulWfNh4D\nAM4zwiIAAAZVdcm62Z9KcvJNaXckua6qvqGqnp7k8iTv3+36AID58xgaAMAFqqpuS7KS5OKqejDJ\nryZZqaorc+IxtNUkP5ck3X1fVb0tyceSHE/yC939tUXUDQDMl7AIAOAC1d3XbzL8hjOs/8okr5xf\nRQDAXuAxNAAAAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIA\nAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbCIgAA\nAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAA\nAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbbhkVVdUtVPVJV964b\ne0VVHauqu8c/12yx7dVVdX9VPVBVh2dZOAAAAACzN8mdRW9McvUm46/q7ivHP3duXFhVFyV5bZJn\nJ3lGkuur6hk7KRYAAACA+do2LOru9yT50hT7virJA9396e7+6yRvSfLcKfYDAAAAwC7ZyXcW/WJV\nfXT8mNqTNll+aZLPrpt/cDwGAAAAwB61b8rtXpfk15P0+PfNSV68k0Kq6mCSg0mytLSU0Wg01X7W\n1tam3navO3Tg+Glju3mu53NvF0lf50dv50dv50dvAQBYtKnCou5++OR0Vf1Wkt/bZLVjSS5bN/+0\n8dhW+zyS5EiSLC8v98rKyjSlZTQaZdpt97obDx89bWz1hpVdO/753NtF0tf50dv50dv50VsAABZt\nqsfQquqSdbM/leTeTVb7QJLLq+rpVfXYJNcluWOa4wEAAACwO7a9s6iqbkuykuTiqnowya8mWamq\nK3PiMbTVJD83XvepSf7P7r6mu49X1cuSvCvJRUlu6e775nIWAAAAAMzEtmFRd1+/yfAbtlj3c0mu\nWTd/Z5I7p64OAAAAgF21k7ehAQAAAHCeERYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAA\nADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAA\nMBAWAQAAADAQFgEAXKCq6paqeqSq7l039m+q6hNV9dGqekdVPXE8vr+qvlpVd49/Xr+4ygGAeRIW\nAQBcuN6Y5OoNY3cl+a7u/vtJ/lOSl69b9qnuvnL889JdqhEA2GX7Fl0A87X/8NHTxlZvunYBlQAA\ne013v6eq9m8Y+/11s+9L8vzdrAkAWDxhEQAAW3lxkreum396Vd2d5NEkv9Ldf7TZRlV1MMnBJFla\nWspoNJp5YUuPSw4dOH7K2DyOc65bW1vTlwno02T0aTL6tD09mswi+yQsAgDgNFX1L5McT3LreOih\nJN/W3V+squ9N8rtV9Z3d/eWN23b3kSRHkmR5eblXVlZmXt+rb709N99z6qXs6g2zP865bjQaZR79\nP9/o02T0aTL6tD09mswi++Q7iwAAOEVV3ZjkOUlu6O5Oku7+q+7+4nj6Q0k+leQ7FlYkADA3wiIA\nAAZVdXWSf57kJ7v7L9eNP6WqLhpPf3uSy5N8ejFVAgDz5DE0AIALVFXdlmQlycVV9WCSX82Jt599\nQ5K7qipJ3jd+89kPJfm1qvqbJF9P8tLu/tJCCgcA5kpYBABwgeru6zcZfsMW6749ydvnWxEAsBd4\nDA0AAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGw\nCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAwb5F\nF8AJ+w8fPW1s9aZrF1AJAAAAcCFzZxEAAAAAA2ERAAAAAANhEQAAAAADYREAAAAAA2ERAAAAAANh\nEQAAAAADYREAAAAAg23Doqq6paoeqap71439m6r6RFV9tKreUVVP3GLb1aq6p6rurqoPzrJwAAAA\nAGZvkjuL3pjk6g1jdyX5ru7++0n+U5KXn2H7H+7uK7t7eboSAQAAANgt24ZF3f2eJF/aMPb73X18\nPPu+JE+bQ20AAAAA7LJ9M9jHi5O8dYtlneQPquprSf59dx/ZaidVdTDJwSRZWlrKaDSaqpi1tbWp\nt12kQweOnza28TwmWWea/U7qXO3tXqev86O386O386O3AAAs2o7Coqr6l0mOJ7l1i1V+oLuPVdW3\nJLmrqj4xvlPpNOMg6UiSLC8v98rKylQ1jUajTLvtIt14+OhpY6s3rJz1OtPsd1Lnam/3On2dH72d\nH72dH70FAGDRpn4bWlXdmOQ5SW7o7t5sne4+Nv79SJJ3JLlq2uMBAAAAMH9ThUVVdXWSf57kJ7v7\nL7dY5/FV9YST00l+PMm9m60LAAAAwN6wbVhUVbcl+eMkV1TVg1X1kiSvSfKEnHi07O6qev143adW\n1Z3jTZeSvLeqPpLk/UmOdvc753IWAAAAAMzEtt9Z1N3XbzL8hi3W/VySa8bTn07y3TuqDgAAAIBd\nNfV3FgEAAABw/hEWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADDY9m1o57P9h4+eMr9607ULqgQA\nAABgb3BnEQAAAAADYREAAAAAA2ERAAAAAANhEQAAAAADYREAAAAAA2ERAAAAAANhEQAAAAADYREA\nAAAAA2ERAAAAAANhEQAAAAADYREAAAAAA2ERAAAAAANhEQAAAAADYREAAAAAA2ERAMAFqqpuqapH\nquredWNPrqq7quqT499PWrfs5VX1QFXdX1U/sZiqAYB5ExYBAFy43pjk6g1jh5O8u7svT/Lu8Xyq\n6hlJrkvyneNtfrOqLtq9UgGA3SIsAgC4QHX3e5J8acPwc5O8aTz9piTPWzf+lu7+q+7+0yQPJLlq\nVwoFAHaVsAgAgPWWuvuh8fTnkyyNpy9N8tl16z04HgMAzjP7Fl0AAAB7U3d3VfXZbldVB5McTJKl\npaWMRqNZl5alxyWHDhw/ZWwexznXra2t6csE9Gky+jQZfdqeHk1mkX0SFgEAsN7DVXVJdz9UVZck\neWQ8fizJZevWe9p47DTdfSTJkSRZXl7ulZWVmRf56ltvz833nHopu3rD7I9zrhuNRplH/883+jQZ\nfZqMPm1PjyazyD55DA0AgPXuSPKi8fSLkty+bvy6qvqGqnp6ksuTvH8B9QEAc+bOIgCAC1RV3ZZk\nJcnFVfVgkl9NclOSt1XVS5J8JskLkqS776uqtyX5WJLjSX6hu7+2kMIBgLkSFsE5Yv/ho6fMr950\n7YIqAeB80d3Xb7HoWVus/8okr5xfRQDAXuAxNAAAAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIA\nAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbCIgAA\nAAAGwiIAAAAABsIiAAAAAAbCIgAAAAAGwiIAAAAABsIiAAAAAAbbhkVVdUtVPVJV964be3JV3VVV\nnxz/ftIW215dVfdX1QNVdXiWhQMAAAAwe5PcWfTGJFdvGDuc5N3dfXmSd4/nT1FVFyV5bZJnJ3lG\nkuur6hk7qhYAAACAudo2LOru9yT50obh5yZ503j6TUmet8mmVyV5oLs/3d1/neQt4+0AAAAA2KP2\nTbndUnc/NJ7+fJKlTda5NMln180/mOSZW+2wqg4mOZgkS0tLGY1GUxW2trY28baHDhw/ZX7aY87C\nxlqS0+uZZJ1p9jups+ntVu459ugp8wcu/aYd7W+3baw/2fk5TNrXvfR5PVfM4jPL5vR2fvQWAIBF\nmzYsGnR3V1XPYD9HkhxJkuXl5V5ZWZlqP6PRKJNue+Pho6fMr94w3TFnYWMtyen1TLLONPud1Nn0\ndtJ6FtnzacyynydN2tdzvXeLMIvPLJvT2/nRWwAAFm3at6E9XFWXJMn49yObrHMsyWXr5p82HgMA\nAABgj5o2LLojyYvG0y9Kcvsm63wgyeVV9fSqemyS68bbAQAAALBHbRsWVdVtSf44yRVV9WBVvSTJ\nTUl+rKo+meRHx/OpqqdW1Z1J0t3Hk7wsybuSfDzJ27r7vvmcBgAAAACzsO13FnX39VssetYm634u\nyTXr5u9McufU1QEAAACwq6Z9DA0AAACA85CwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgA\nAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAA\nAICBsAgAAACAgbAIAAAAgIGwCAAAAIDBvkUXsJv2Hz66sP2u3nTtXPYLAAAAMEvuLAIAAABgICwC\nAAAAYCAsAgAAAGAgLAIAAABgICwCAAAAYCAsAgAAAGAgLAIAAABgICwCAAAAYCAsAgAAAGCwb9EF\nAACwt1TVFUneum7o25P8qyRPTPJPk/zZePxfdPedu1weADBnwiIAAE7R3fcnuTJJquqiJMeSvCPJ\nzyZ5VXf/2wWWBwDMmcfQAAA4k2cl+VR3f2bRhQAAu0NYBADAmVyX5LZ1879YVR+tqluq6kmLKgoA\nmB+PoQEAsKmqemySn0zy8vHQ65L8epIe/745yYs32e5gkoNJsrS0lNFoNPPalh6XHDpw/JSxeRzn\nXLe2tqYvE9CnyejTZPRpe3o0mUX2SVgEAMBWnp3kw939cJKc/J0kVfVbSX5vs426+0iSI0myvLzc\nKysrMy/s1bfenpvvOfVSdvWG2R/nXDcajTKP/p9v9Gky+jQZfdqeHk1mkX3yGBoAAFu5PuseQauq\nS9Yt+6kk9+56RQDA3LmzCACA01TV45P8WJKfWzf8r6vqypx4DG11wzIA4DwhLAIA4DTd/ZUk37xh\n7GcWVA4AsIs8hgYAAADAQFgEAAAAwEBYBAAAAMDAdxats//w0W3XWb3p2l2oBPa2zf5W/G0AAACc\nH9xZBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBg6rCoqq6o\nqrvX/Xy5qn55wzorVfXounX+1c5LBgAAAGBe9k27YXffn+TKJKmqi5IcS/KOTVb9o+5+zrTHAQCA\nSew/fPSU+dWbrl1QJQBwbpvVY2jPSvKp7v7MjPYHAAAAwAJMfWfRBtcluW2LZf+wqj6aE3ce/bPu\nvm+zlarqYJKDSbK0tJTRaDRVIWtra1tue+jA8an2ud5m+55kv9udz7S1TbPfefR2Uhvr2en+dtss\n+3nSpH3dS72bRx/mYRafWTant/OjtwAALNqOw6KqemySn0zy8k0WfzjJt3X3WlVdk+R3k1y+2X66\n+0iSI0myvLzcKysrU9UzGo2y1bY3brg1eRqrN5y+70n2u9l2Z7uPWe13u222cqbeTmpjPdPWsiiz\n7OdJk/Z1L/VuHn2Yh1l8Ztmc3s6P3gIAsGizeAzt2Uk+3N0Pb1zQ3V/u7rXx9J1JHlNVF8/gmAAA\nAADMwSzCouuzxSNoVfWtVVXj6avGx/viDI4JAAAAwBzs6DG0qnp8kh9L8nPrxl6aJN39+iTPT/Lz\nVXU8yVeTXNfdvZNjAgAAADA/OwqLuvsrSb55w9jr102/JslrdnIMAAAAAHbPLB5DAwAAAOA8ISwC\nAAAAYCAsAgAAAGAgLAIAAABgICwCAAAAYCAsAgAAAGCwb9EFnGv2Hz666BJOsbGe1ZuuXchxd/PY\nnLsW9XkFAABgcu4sAgAAAGAgLAIAAABgICwCAAAAYCAsAgAAAGAgLAIAAABgICwCAAAAYCAsAgAA\nAGAgLAIAAABgICwCAAAAYCAsAgAAAGAgLAIAAABgICwCAAAAYCAsAgAAAGAgLAIAAABgICwCAAAA\nYCAsAgAAAGAgLAIAAABgICwCAAAAYCAsAgAAAGAgLAIAAABgICwCAAAAYLBv0QVcqPYfPrroEubu\nQjhHAAAAON+4swgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIG3oQEAcJqqWk3yF0m+\nluR4dy9X1ZOTvDXJ/iSrSV7Q3X++qBoBgPlwZxEAAFv54e6+sruXx/OHk7y7uy9P8u7xPABwnhEW\nAQAwqecmedN4+k1JnrfAWgCAOREWAQCwmU7yB1X1oao6OB5b6u6HxtOfT7K0mNIAgHnynUUAAGzm\nB7r7WFV9S5K7quoT6xd2d1dVb7bhOFw6mCRLS0sZjUYzL27pccmhA8fPuM48jnuuWVtb04cJ6NNk\n9Gky+rQ9PZrMIvskLAIA4DTdfWz8+5GqekeSq5I8XFWXdPdDVXVJkke22PZIkiNJsry83CsrKzOv\n79W33p6b7znzpezqDbM/7rlmNBplHv0/3+jTZPRpMvq0PT2azCL75DE0AABOUVWPr6onnJxO8uNJ\n7k1yR5J0cEf7AAAgAElEQVQXjVd7UZLbF1MhADBP7iwCAGCjpSTvqKrkxPXib3f3O6vqA0neVlUv\nSfKZJC9YYI0AwJwIiwAAOEV3fzrJd28y/sUkz9r9igCA3eQxNAAAAAAGwiIAAAAABsIiAAAAAAbC\nIgAAAAAGOwqLqmq1qu6pqrur6oObLK+q+o2qeqCqPlpV37OT4wEAAAAwX7N4G9oPd/cXtlj27CSX\nj3+emeR1498AAAAA7EHzfgztuUne3Ce8L8kTq+qSOR8TAAAAgCntNCzqJH9QVR+qqoObLL80yWfX\nzT84HgMAAABgD9rpY2g/0N3HqupbktxVVZ/o7vdMs6Nx2HQwSZaWljIajaYqaG1tbcttDx04PtU+\nZ2FjTfOqZZLjTNPbe449mqXHJa++9fbxfk9f5+Syvz329vud9p/zLNxz7NFT5g9c+k3brrPZOe30\nHM70mT312Kf+s1xk76b9XO32OUzaW86e3s6P3gIAsGg7Cou6+9j49yNV9Y4kVyVZHxYdS3LZuvmn\njcc229eRJEeSZHl5uVdWVqaqaTQaZattbzx8dKp9zsLqDSunzM+rlkmOs3GdSdx4+GgOHTiem++Z\nxddc7ayWWdnYm81qmeSf007P4Uyf2TPVspd6l0xWz26fw6S95ezp7fzoLQAAizb1Y2hV9fiqesLJ\n6SQ/nuTeDavdkeSF47eifV+SR7v7oamrBQAAAGCudnKbyFKSd1TVyf38dne/s6pemiTd/fokdya5\nJskDSf4yyc/urFwAAAAA5mnqsKi7P53kuzcZf/266U7yC9MeAwAAAIDdtdO3oQEAAABwHhEWAQAA\nADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAA\nMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADDYt+gCLhT7\nDx9ddAl70sa+rN507VlvM+l20+x3XtYf69CB41nZtSNz0jSfvVkcZzPzOjYAAMA03FkEAAAAwEBY\nBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgE\nAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMBAWAQA\nAADAQFgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAAwGDfogtgtvYfPjqTbVZvunYW5Zy1edYyTW9m\ncZxF9TKZ7JwnqW+3esff2kufIwAA4MLiziIAAE5RVZdV1R9W1ceq6r6q+qXx+Cuq6lhV3T3+uWbR\ntQIAs+fOIgAANjqe5FB3f7iqnpDkQ1V113jZq7r73y6wNgBgzoRFAACcorsfSvLQePovqurjSS5d\nbFUAwG4RFgEAsKWq2p/kHyT5j0m+P8kvVtULk3wwJ+4++vNNtjmY5GCSLC0tZTQazbyupcclhw4c\nP+M68zjuuWZtbU0fJqBPk9GnyejT9vRoMovsk7AIAIBNVdXfTfL2JL/c3V+uqtcl+fUkPf59c5IX\nb9yuu48kOZIky8vLvbKyMvPaXn3r7bn5njNfyq7eMPvjnmtGo1Hm0f/zjT5NRp8mo0/b06PJLLJP\nvuAaAIDTVNVjciIourW7fydJuvvh7v5ad389yW8luWqRNQIA8yEsAgDgFFVVSd6Q5OPd/e/WjV+y\nbrWfSnLvbtcGAMzf1I+hVdVlSd6cZCknbkU+0t3/x4Z1VpLcnuRPx0O/092/Nu0xAQDYFd+f5GeS\n3FNVd4/H/kWS66vqypy49ltN8nOLKQ8AmKedfGfRpq9U7e6PbVjvj7r7OTs4DgAAu6i735ukNll0\n527XAgDsvqkfQ+vuh7r7w+Ppv0jilaoAAAAA57iZvA1twytVN/qHVfXRJMeS/LPuvm+LfczkFatn\nerXcdq9XvVBs7M9mfdlsnUleUTsP09S7mXnVvl19m9W2fp2lx01X/6zOeZH7mfdrIM/m3wfzqmXa\n3u12r86W153Oj94CALBoOw6LNr5SdcPiDyf5tu5eq6prkvxukss328+sXrF6plfL3Xj46FT7PN9s\nfI3sZn3ZbJ1DB45v+4raeZim3s3M65//dvVtVtv6dQ4dOJ4XTPB5n2S/222zmUXuZ96vND6bfx/M\nq5Zpe7fbvTpbXnc6P3oLAMCi7ehtaJu9UnW97v5yd6+Np+9M8piqungnxwQAAABgfqYOi7Z6peqG\ndb51vF6q6qrx8b447TEBAAAAmK+dPFO01StVvy1Juvv1SZ6f5Oer6niSrya5rrt7B8cEAAAAYI6m\nDovO8ErV9eu8Jslrpj0GAAAAALtrR99ZBAAAAMD5RVgEAAAAwEBYBAAAAMBAWAQAAADAQFgEAAAA\nwGDqt6Fxftt/+OiiSxjspVo2s119k9Q/zTluts3qTdcubD/zMklv5lXvIo+9Wzae47l+PgAAwM65\nswgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAICBsAgAAACAgbAIAAAAgIGw\nCAAAAICBsAgAAACAgbAIAAAAgIGwCAAAAIDBvkUXAAAAe8X+w0dPG1u96doFVAIAi+POIgAAAAAG\n7iwCAOC85C4hAJiOO4sAAAAAGAiLAAAAABgIiwAAAAAYCIsAAAAAGAiLAAAAABgIiwAAAAAYCIsA\nAAAAGOxbdAHsvv2Hjy66hJk7H89pGovswzTH3rjN6k3XzrSWQweO58bDR2e23zMd66RpjjVJ72bV\nq738t7JZbZOc5zS9mddnb7vjzOpY89ovXAj28r8HAWCvcGcRAAAAAANhEQAAAAADYREAAAAAA2ER\nAAAAAANhEQAAAAADYREAAAAAA2ERAAAAAANhEQAAAAADYREAAAAAg32LLgAAAPay/YePnjK/etO1\nC6oEAHaHO4sAAAAAGLizCAAAdsjdRwCcT9xZBAAAAMBAWAQAAADAQFgEAAAAwEBYBAAAAMDAF1wD\nAMBZ2Phl1pOu40uvAThXuLMIAAAAgMGOwqKqurqq7q+qB6rq8CbLq6p+Y7z8o1X1PTs5HgAAi7fd\nNSAAcG6b+jG0qrooyWuT/FiSB5N8oKru6O6PrVvt2UkuH/88M8nrxr8BADgHTXgNyCY2Ppq28bG0\nSR5vO1uHDhzPygTreWwO5sffF9vZi5+RndxZdFWSB7r7093910nekuS5G9Z5bpI39wnvS/LEqrpk\nB8cEAGCxJrkGBADOYdXd021Y9fwkV3f3/zie/5kkz+zul61b5/eS3NTd7x3PvzvJ/9rdH9xkfweT\nHBzPXpHk/qkKSy5O8oUpt+XM9HY+9HV+9HZ+9HZ+9lpv/5vufsqii2DvmPAacFbXdWey1/5W9ip9\nmow+TUafJqNP29OjycyjTxNd2+2Zt6F195EkR3a6n6r6YHcvz6AkNtDb+dDX+dHb+dHb+dFbzgez\nuq47E38rk9GnyejTZPRpMvq0PT2azCL7tJPH0I4luWzd/NPGY2e7DgAA5w7XdwBwnttJWPSBJJdX\n1dOr6rFJrktyx4Z17kjywvFb0b4vyaPd/dAOjgkAwGJNcg0IAJzDpn4MrbuPV9XLkrwryUVJbunu\n+6rqpePlr09yZ5JrkjyQ5C+T/OzOS97WXG95vsDp7Xzo6/zo7fzo7fzoLXvaVteACyjF38pk9Gky\n+jQZfZqMPm1PjyazsD5N/QXXAAAAAJx/dvIYGgAAAADnGWERAAAAAIPzJiyqqqur6v6qeqCqDi+6\nnnNdVa1W1T1VdXdVfXA89uSququqPjn+/aRF13kuqKpbquqRqrp33diWvayql48/x/dX1U8spupz\nwxa9fUVVHRt/du+uqmvWLdPbCVTVZVX1h1X1saq6r6p+aTzuc7tDZ+itzy2chQv9um9W1xZV9b3j\n670Hquo3qqp2+1zmZZb/W3ae9+kbq+r9VfWRcZ/+9/G4Pm1QVRdV1Z9U1e+N5/VogzrL/w95Affp\niVX1H6rqE1X18ar67/Zkn7r7nP/JiS9X/FSSb0/y2CQfSfKMRdd1Lv8kWU1y8Yaxf53k8Hj68P/P\n3v0H6XbXdYJ/fySAboJABLuyBPfG3QyzQDTKLZYpGKYxoggUwZmpDCxCGFijuxSlNdmSi1rKSlGV\n2V1xpmpmtCIwhB0gZAQkBY67GO1lnFU00QiBwATwZkgmydWAwGUUvfDZP/rcb57bt+9z8+N5+um+\n/XpVPfWc8z3P6fPtzz23+9vv8yvJP111P/fCK8mzk3xvkltOV8skT57230cmuWDarx+26u9ht75O\nUds3JPlft/ms2t7/up6X5Hun6Ucl+Y9T/ey3y6ut/dbL636+jPsWN7ZI8gdJnpGkkvy7JD+06u9t\ngTVa2O+yM7xOleScafrhST46fa/qdHKt/kmSdyX54DSvRifX6HDu59+Q+7xO1yT5n6bpRyR5zG6s\n05lyZtHTk3ymuz/X3X+d5Nokl664T2eiS7O5Y2d6f/EK+7JndPdHknxhS/Opanlpkmu7+2vd/afZ\nfJLg03eko3vQKWp7Kmp7P3X3Xd39R9P0V5LcmuQJsd8+ZHNqeypqCyfb9+O+RYwtquq8JN/a3b/f\nm391vCNn0NhuUb/L9kGduruPTrMPn14ddTpBVZ2f5AVJ3jLTrEb3jzrNqKpHZzPwf2uSdPdfd/df\nZBfW6UwJi56Q5PMz83dk/uCb0+skv1VVN1XVFVPbWnffNU3fnWRtNV07I5yqlvblxXhtVX1sOk3/\n+CmcavsgVNWBJN+TzSON9tsF2lLbxH4L95f/F9t7oD+jnzBNb20/4zzE32VnfJ2my6tuTnIkyYe7\nW51O9s+S/FSSb8y0qdHJHsjfkPu1Thck+bMk/3q6rPEtVXV2dmGdzpSwiMV7VndfnOSHkrymqp49\nu3BKL3slPTvDqOXC/XI2L024OMldSX5xtd3Zu6rqnCTvTfKT3f3l2WX224dmm9rab4GF8TP6Pn6X\nnV53f30a95+fzTMWnrpl+b6uU1W9MMmR7r7pVJ/Z7zWa4W/I0zsrm5cR/3J3f0+Sr2bzsrNht9Tp\nTAmL7kzyxJn586c2HqTuvnN6P5Lk/dk85fue6XS3TO9HVtfDPe9UtbQvP0Tdfc806PlGkl/NfZfs\nqO0DUFUPz+bg+p3d/b6p2X67ANvV1n4LD4j/F9t7oD+j75ymt7afMRb0u+yMr9Nx06Uwv5PkeVGn\nWc9M8qKqOpzNy16/r6r+TdToJA/wb8j9Wqc7ktwxncGXJL+WzfBo19XpTAmL/jDJhVV1QVU9IslL\nkly/4j7tWVV1dlU96vh0kh9Icks2a3r59LHLk3xgNT08I5yqltcneUlVPbKqLkhyYTZvXMb9dPyH\n7OSHs7nvJmp7v01PUnhrklu7+80zi+y3D9Gpamu/hQfEuG97D+hn9HS5w5er6hnTz6ZX5Awa2y3q\nd9k+qNPjq+ox0/S3JHlukk9FnYbufn13n9/dB7L58+a3u/tHokYneBB/Q+7LOnX33Uk+X1VPmpou\nSfLJ7MY69S64G/giXkmen82nHHw2yc+suj97+ZXNSyH+ZHp94ng9k3xbkhuS3Jbkt5Kcu+q+7oVX\nkndn87KSv8lmkvzqebVM8jPTfvzpnGF3/t+h2v5fST6e5GPTD9fz1PYB1/VZ2Tz19WNJbp5ez7ff\nLrW29lsvrwfw2u/jvkWNLZIczOYfc59N8i+S1Kq/twXWaGG/y87wOn1Xkj+e6nRLkp+b2tVp+3qt\n576noanRibV5wH9D7sc6Td/fxUlunP7f/XqSx+7GOtW0EQAAAAA4Yy5DAwAAAGABhEUAAAAADMIi\nAAAAAAZhEQAAAACDsAgAAACAQVgEAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAA\nAAAGYREAAAAAg7AIAAAAgEFYBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAA\nBmERAAAAAIOwCAAAAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZh\nEQAAAACDsAgAAACAQVgEAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREA\nAAAAg7AIAAAAgEFYBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAA\nAIOwCAAAAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACD\nsAgAAACAQVgEAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AI\nAAAAgEFYBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAA\nAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACA\nQVgEAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgEFY\nBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQA\nAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgEAAAA\nwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgEFYBAAAAMAg\nLAIAAABgEBYBJ6iq36yqX9im/dKquruqznqAX+9xVfUfqureqvpSVf1eVT1zZvmvVNXRmdfXquor\ni/heAAD2u0WP7aZ1u6q+OjN+e8vMMmM7OANUd6+6D8AuUlUvTfKmJP9tz/yAqKpfS3J7d1/5AL7W\nWUnOSnJBktuSfD3JpUneluTbu/vYNuu8Pck3uvtVD+X7AABg8WO77j5WVZ3kwu7+zP1Y5+0xtoM9\nx5lFwFa/nuTbkvzd4w1V9dgkL0zyjqp6QVX9cVV9uao+X1VvmPncgelI06ur6j8l+e3u/qvuvnUK\nhiqbgdFjk5y7dcNVdXaSf5DkmmV+gwAA+8hCx3YPZMPGdrB3CYuAE3T3Xya5LskrZpovS/Kp7v6T\nJF+dlj0myQuS/M9V9eItX+bvJfnvk/zg8Yaq+liSv0pyfZK3dPeRbTb/D5L8WZKPLOa7AQDY35Y1\ntkvykekytvdV1YFTbN7YDvYoYRGwnWuS/MOq+uZp/hVTW7p7o7s/3t3f6O6PJXl3NgcQs97Q3V+d\nBieZ1vuuJN+a5H9M8run2O7lSd7Rro8FAFikRY/t/l6SA0n+dpL/nOSDp7j3kbEd7FHuWQRsq6o+\nk+Rnk/xhkk8lOb+776mq/yHJVUmemuQRSR6Z5N9298uno0p/muQR3f03c772rUleMh3NOt72HdO6\nF3b355bzXQEA7E/LGttV1cOSfCnJ3+nuj8+0G9vBHubMIuBU3pHNo04/kuT/7u57pvZ3ZfNSsid2\n96OT/Eo270U063Qp9MOTfOeWtpcn+Q8GEwAAS7HMsV22WcfYDvYwYRFwKu9I8v1JfjQn3pTwUUm+\n0N1/VVVPz+ZlZadUVc+oqmdV1SOq6luq6nVJ1pJ8dMtHX5Hk7QvrPQAAsxY1tntKVV1cVQ+rqnOS\nvDnJnUlu3fJRYzvYw4RFwLa6+3CS/y/J2dk82nTc/5LkF6rqK0l+Lps3TJznkUn+ZZJ7szmQeH6S\nF3T3fz7+gar6O0nOT/JvF9V/AADus8Cx3VqS9yT5cpLPJflvkrxw9jI1YzvY+9yzCAAAAIDBmUUA\nAAAADMIiAAAAAAZhEQAAAACDsAgAAACA4axVd2A7j3vc4/rAgQOr7sau8tWvfjVnn332qruxr6j5\naqj7aqj7auyFut90001/3t2PX3U/2LuOj+v2wv6+Suozn/rMpz6np0bzqc98Z1J97u/YbleGRQcO\nHMiNN9646m7sKhsbG1lfX191N/YVNV8NdV8NdV+NvVD3qrp91X1gbzs+rtsL+/sqqc986jOf+pye\nGs2nPvOdSfW5v2M7l6EBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQA\nAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgEAAAA\nwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAw1mr7gDsJQcOfeiktsNX\nvWAFPQEAgJNtHa8aqwIPhjOLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQAAADA\nICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgEAAAAwCAs\nAgAAAGAQFgEA7FNV9baqOlJVt8y0vaeqbp5eh6vq5qn9QFX95cyyX1ldzwGAZTpr1R0AAGBl3p7k\nXyR5x/GG7v5Hx6er6heTfGnm85/t7ot3rHcAwEoIiwAA9qnu/khVHdhuWVVVksuSfN9O9gkAWD1h\nEQAA2/m7Se7p7ttm2i6YLkv7UpKf7e5/v92KVXVFkiuSZG1tLRsbGzl69Gg2NjaW3ec9S33mU5/5\nZutz5UXHTlimbpvsQ/Opz3z7sT7CIgAAtvPSJO+emb8ryXd0971V9bQkv15VT+nuL29dsbuvTnJ1\nkhw8eLDX19ezsbGR9fX1nej3nqQ+86nPfLP1eeWhD52w7PDL1ne+Q7uQfWg+9ZlvP9ZnYTe4rqon\nzdzw8Oaq+nJV/WRVnVtVH66q26b3xy5qmwAALF5VnZXk7yd5z/G27v5ad987Td+U5LNJ/tZqeggA\nLNPCwqLu/nR3Xzzd9PBpSf5LkvcnOZTkhu6+MMkN0zwAALvX9yf5VHffcbyhqh5fVQ+bpr8zyYVJ\nPrei/gEAS7SwsGiLS7L5tIzbk1ya5Jqp/ZokL17SNgEAeACq6t1Jfi/Jk6rqjqp69bToJTnxErQk\neXaSj033LPq1JD/e3V/Yud4CADtlWfcsmh1grHX3XdP03UnWtlthuxshcp/9eEOtVduu5ltvGJi4\naeCi2ddXQ91XQ91Zte5+6SnaX7lN23uTvHfZfQIAVm/hYVFVPSLJi5K8fuuy7u6q6u3W2+5GiNxn\nP95Qa9W2q/nWGwYmbhq4aPb11VD31VB3AAB2o2VchvZDSf6ou++Z5u+pqvOSZHo/soRtAgAAALAA\nywiLtj5m9fokl0/Tlyf5wBK2CQAAAMACLDQsqqqzkzw3yftmmq9K8tyqui2bT9a4apHbBAAAAGBx\nFnrPou7+apJv29J2bzafjgYAAADALreMy9AAAAAA2KOERQAAAAAMwiIAAAAABmERAAAAAIOwCAAA\nAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACA\nQVgEAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgEFY\nBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQA\nAADAcNaqOwBnugOHPnRS2+GrXrCCngAAAMDpObMIAAAAgEFYBAAAAMAgLAIAAABgEBYBAAAAMAiL\nAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAA\nAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAYJ+qqrdV1ZGqumWm7Q1VdWdV3Ty9nj+z7PVV9Zmq\n+nRV/eBqeg0ALJuwCABg/3p7kudt0/5L3X3x9PqNJKmqJyd5SZKnTOv8q6p62I71FADYMcIiAIB9\nqrs/kuQL9/Pjlya5tru/1t1/muQzSZ6+tM4BACsjLAIAYKvXVtXHpsvUHju1PSHJ52c+c8fUBgCc\nYc5a5BerqsckeUuSpybpJK9K8ukk70lyIMnhJJd19xcXuV0AABbml5O8MZtjuTcm+cVsjunut6q6\nIskVSbK2tpaNjY0cPXo0GxsbC+7qmUN95lOf+Wbrc+VFx05Ypm6b7EPzqc98+7E+Cw2LkvzzJL/Z\n3f+wqh6R5L9K8tNJbujuq6rqUJJDSV634O0CALAA3X3P8emq+tUkH5xm70zyxJmPnj+1bfc1rk5y\ndZIcPHiw19fXs7GxkfX19aX0+UygPvOpz3yz9XnloQ+dsOzwy9Z3vkO7kH1oPvWZbz/WZ2GXoVXV\no5M8O8lbk6S7/7q7/yKb17dfM33smiQvXtQ2AQBYrKo6b2b2h5Mcf1La9UleUlWPrKoLklyY5A92\nun8AwPIt8syiC5L8WZJ/XVXfneSmJD+RZK2775o+c3eStQVuEwCAB6mq3p1kPcnjquqOJD+fZL2q\nLs7mZWiHk/xYknT3J6rquiSfTHIsyWu6++ur6DcAsFyLDIvOSvK9SV7b3R+tqn+ezUvOhu7uqurt\nVt7u2nbusx+vkVy17Wq+9Rrw5PTXgT+YdfYz+/pqqPtqqDur1t0v3ab5rXM+/6Ykb1pejwCA3WCR\nYdEdSe7o7o9O87+WzbDonqo6r7vvmk5rPrLdyttd28599uM1kqu2Xc23XgOenP468Aezzn5mX18N\ndV8NdQcAYDda2D2LuvvuJJ+vqidNTZdk8zTl65NcPrVdnuQDi9omAAAAAIu16KehvTbJO6cnoX0u\nyT/OZiB1XVW9OsntSS5b8DYBAAAAWJCFhkXdfXOSg9ssumSR2wEAAABgORZ2GRoAAAAAe5+wCAAA\nAGwg38AAAB6vSURBVIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZh\nEQAAAACDsAgAAACAQVgEAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREA\nAAAAg7AIAAAAgEFYBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAA\nAIOwCAAAAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACD\nsAgAAACAQVgEAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AI\nAAAAgEFYBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCABg\nn6qqt1XVkaq6Zabt/6iqT1XVx6rq/VX1mKn9QFX9ZVXdPL1+ZXU9BwCWSVgEALB/vT3J87a0fTjJ\nU7v7u5L8xySvn1n22e6+eHr9+A71EQDYYcIiAIB9qrs/kuQLW9r+n+4+Ns3+fpLzd7xjAMBKnbXI\nL1ZVh5N8JcnXkxzr7oNVdW6S9yQ5kORwksu6+4uL3C4AAEvxqmyO4467oKpuTvKlJD/b3f9+u5Wq\n6ookVyTJ2tpaNjY2cvTo0WxsbCy7v3uW+synPvPN1ufKi46dsEzdNtmH5lOf+fZjfRYaFk2e091/\nPjN/KMkN3X1VVR2a5l+3hO0CALAgVfUzSY4leefUdFeS7+jue6vqaUl+vaqe0t1f3rpud1+d5Ook\nOXjwYK+vr2djYyPr6+s71Pu9R33mU5/5ZuvzykMfOmHZ4Zet73yHdiH70HzqM99+rM9OXIZ2aZJr\npulrkrx4B7YJAMCDVFWvTPLCJC/r7k6S7v5ad987Td+U5LNJ/tbKOgkALM2iw6JO8ltVddN0+nGS\nrHX3XdP03UnWFrxNAAAWpKqel+Snkryou//LTPvjq+ph0/R3JrkwyedW00sAYJkWfRnas7r7zqr6\n9iQfrqpPzS7s7q6q3m7F7a5t5z778RrJVduu5luvAU9Ofx34g1lnP7Ovr4a6r4a6s2pV9e4k60ke\nV1V3JPn5bD797JHZHMslye9PTz57dpJfqKq/SfKNJD/e3V/Y9gsDAHvaQsOi7r5zej9SVe9P8vQk\n91TVed19V1Wdl+TIKdY96dp27rMfr5Fcte1qvvUa8OT014E/mHX2M/v6aqj7aqg7q9bdL92m+a2n\n+Ox7k7x3uT0CAHaDhV2GVlVnV9Wjjk8n+YEktyS5Psnl08cuT/KBRW0TAAAAgMVa5JlFa0neP52u\nfFaSd3X3b1bVHya5rqpeneT2JJctcJsAAAAALNDCwqLu/lyS796m/d4klyxqOwAAAAAsz6KfhgYA\nAADAHiYsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgEFYBAAA\nAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQAAADA\nICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgEAAAAwCAs\nAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgEFYBAAAAMAgLAIA\nAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQAAADAICwCAAAA\nYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgEAAAAwCAsAgDYp6rq\nbVV1pKpumWk7t6o+XFW3Te+PnVn2+qr6TFV9uqp+cDW9BgCWTVgEALB/vT3J87a0HUpyQ3dfmOSG\naT5V9eQkL0nylGmdf1VVD9u5rgIAO0VYBACwT3X3R5J8YUvzpUmumaavSfLimfZru/tr3f2nST6T\n5Ok70lEAYEctNCyqqodV1R9X1Qen+VOexgwAwK601t13TdN3J1mbpp+Q5PMzn7tjagMAzjBnLfjr\n/USSW5N86zR//DTmq6rq0DT/ugVvEwCAJejurqp+oOtV1RVJrkiStbW1bGxs5OjRo9nY2Fh0F88Y\n6jOf+sw3W58rLzp2wjJ122Qfmk995tuP9VlYWFRV5yd5QZI3JfknU/OlSdan6WuSbERYBACwm91T\nVed1911VdV6SI1P7nUmeOPO586e2k3T31UmuTpKDBw/2+vp6NjY2sr6+vsRu723qM5/6zDdbn1ce\n+tAJyw6/bH3nO7QL2YfmU5/59mN9Fnlm0T9L8lNJHjXTdqrTmE+y3REo7rMfk8xV267mW4/UJKc/\nWvNg1tnP7Ouroe6roe7sUtcnuTzJVdP7B2ba31VVb07yXye5MMkfrKSHAMBSLSQsqqoXJjnS3TdV\n1fp2nzndaczbHYHiPvsxyVy17Wq+9UhNcvqjNQ9mnf3Mvr4a6r4a6s6qVdW7s3kW+OOq6o4kP5/N\nkOi6qnp1ktuTXJYk3f2JqrouySeTHEvymu7++ko6DgAs1aLOLHpmkhdV1fOTfHOSb62qf5NTn8YM\nAMCKdfdLT7HoklN8/k3ZvOUAAHAGW8jT0Lr79d19fncfSPKSJL/d3T+S+05jTk48jRkAAACAXWgh\nYdEcVyV5blXdluT7p3kAAAAAdqlF3uA6SdLdG9l86lm6+96c4jRmAAAAAHafZZ9ZBAAAAMAeIiwC\nAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgEAAAAwCAsAgAA\nAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgEFYBAAAAMAgLAIAAABg\nEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQAAADAICwCAAAAYBAW\nAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgEAAAAwCAsAgAAAGAQFgEA\nAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgEFYBAAAAMAgLAIAAABgEBYBAAAA\nMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQAAADAICwCAAAAYDhr1R0AAGB3\nqaonJXnPTNN3Jvm5JI9J8qNJ/mxq/+nu/o0d7h4AsGTCIgAATtDdn05ycZJU1cOS3Jnk/Un+cZJf\n6u7/c4XdAwCWbGGXoVXVN1fVH1TVn1TVJ6rqf5vaz62qD1fVbdP7Yxe1TQAAlu6SJJ/t7ttX3REA\nYGcs8syiryX5vu4+WlUPT/K7VfXvkvz9JDd091VVdSjJoSSvW+B2AQBYnpckeffM/Gur6hVJbkxy\nZXd/cesKVXVFkiuSZG1tLRsbGzl69Gg2NjZ2or97kvrMpz7zzdbnyouOnbBM3TbZh+ZTn/n2Y30W\nFhZ1dyc5Os0+fHp1kkuTrE/t1yTZiLAIAGDXq6pHJHlRktdPTb+c5I3ZHOO9MckvJnnV1vW6++ok\nVyfJwYMHe319PRsbG1lfX9+Jbu9J6jOf+sw3W59XHvrQCcsOv2x95zu0C9mH5lOf+fZjfRZ6z6Lp\nmvabkvx3Sf5ld3+0qta6+67pI3cnWTvFuicdgeI++zHJXLXtar71SE1y+qM1D2ad/cy+vhrqvhrq\nzh7wQ0n+qLvvSZLj70lSVb+a5IOr6hgAsDwLDYu6++tJLq6qxyR5f1U9dcvyrqo+xbonHYHiPvsx\nyVy17Wq+9UhNcvqjNQ9mnf3Mvr4a6r4a6s4e8NLMXIJWVefNHAT84SS3rKRXAMBSLeVpaN39F1X1\nO0mel+Se4wOLqjovyZFlbBMAgMWpqrOTPDfJj800/+9VdXE2L0M7vGUZAHCGWFhYVFWPT/I3U1D0\nLdkcXPzTJNcnuTzJVdP7Bxa1TQAAlqO7v5rk27a0vXxF3QEAdtAizyw6L8k1032LvinJdd39war6\nvSTXVdWrk9ye5LIFbhMAAACABVrk09A+luR7tmm/N8kli9oOAAAAAMvzTavuAAAAAAC7h7AIAAAA\ngEFYBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBB\nWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgE\nAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgEFYBAAA\nAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAAAIBBWAQAAADA\nICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACAQVgEAAAAwCAs\nAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AIAAAAgOGsVXcAAIDdp6oO\nJ/lKkq8nOdbdB6vq3CTvSXIgyeEkl3X3F1fVRwBgOZxZBADAqTynuy/u7oPT/KEkN3T3hUlumOYB\ngDPMwsKiqnpiVf1OVX2yqj5RVT8xtZ9bVR+uqtum98cuapsAAOyoS5NcM01fk+TFK+wLALAkizyz\n6FiSK7v7yUmekeQ1VfXkOAIFALAXdZLfqqqbquqKqW2tu++apu9OsraargEAy7SwexZNA4e7pumv\nVNWtSZ6QzSNQ69PHrkmykeR1i9ouAABL8azuvrOqvj3Jh6vqU7MLu7urqrdbcQqXrkiStbW1bGxs\n5OjRo9nY2Fh6p/cq9ZlPfeabrc+VFx07YZm6bbIPzac+8+3H+lT3tr/jH9oXrTqQ5CNJnprkP3X3\nY6b2SvLF4/Nb1pkdVDzt2muvXXi/9rKjR4/mnHPOWXU39pXtav7xO7900ucuesKj536dB7POfmZf\nXw11X429UPfnPOc5N83cr4Z9qqrekORokh9Nst7dd1XVeUk2uvtJ89Y9ePBg33jjjdnY2Mj6+vry\nO7tHqc986jPfbH0OHPrQCcsOX/WCFfRo97EPzac+851J9amq+zW2W/jT0KrqnCTvTfKT3f3lzXxo\n07wjUN19dZKrk81BxZnyD7EoZ9LOuVdsV/NXbvnlmySHX7Z+UttDXWc/s6+vhrqvhrqzW1XV2Um+\naTpb/OwkP5DkF5Jcn+TyJFdN7x9YXS8BgGVZaFhUVQ/PZlD0zu5+39R8T1WdN3ME6sgitwkAwMKt\nJXn/dNDvrCTv6u7frKo/THJdVb06ye1JLlthHwGAJVlYWDRdYvbWJLd295tnFjkCBQCwh3T355J8\n9zbt9ya5ZOd7BADspEWeWfTMJC9P8vGqunlq++lshkSOQAEAAADsAYt8GtrvJqlTLHYECgAAAGAP\n+KZVdwAAAACA3UNYBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAA\nAIOwCAAAAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACD\nsAgAAACAQVgEAAAAwCAsAgAAAGAQFgEAAAAwCIsAAAAAGIRFAAAAAAzCIgAAAAAGYREAAAAAg7AI\nAAAAgEFYBAAAAMAgLAIAAABgEBYBAAAAMAiLAAAAABiERQAAAAAMwiIAAAAABmERAAAAAIOwCAAA\nAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAAAADMIiAAAAAAZhEQAAAACDsAgAAACA\nQVgEAAAAwCAsAgAAAGA4a9UdABbnwKEPnTB/+KoXrKgnAAAA7FXOLAIAAABgEBYBAAAAMAiLAAAA\nABiERQAAAAAMwiIAAAAABk9D28Vmn2x15UXHsn6azySefgUAAAA8NM4sAgAAAGAQFgEAcIKqemJV\n/U5VfbKqPlFVPzG1v6Gq7qyqm6fX81fdVwBg8RYWFlXV26rqSFXdMtN2blV9uKpum94fu6jtAQCw\nNMeSXNndT07yjCSvqaonT8t+qbsvnl6/sbouAgDLssgzi96e5Hlb2g4luaG7L0xywzQPAMAu1t13\ndfcfTdNfSXJrkiestlcAwE5Z2A2uu/sjVXVgS/Olybgv8zVJNpK8blHbBABguabx3fck+WiSZyZ5\nbVW9IsmN2Tz76IvbrHNFkiuSZG1tLRsbGzl69Gg2NjZ2qtt7jvrMpz7zzdbnyouOnbBM3TbZh+ZT\nn/n2Y32quxf3xTYHEx/s7qdO83/R3Y+ZpivJF4/Pb7Pu7KDiaddee+3C+rVIH7/zSye1XfSERy99\nW2vfknz7uSdvZ2t/tvZlJ/t7pjl69GjOOeecE9oeTD1Xtc8sczvLtF3dWT51X429UPfnPOc5N3X3\nwVX3g9WoqnOS/L9J3tTd76uqtSR/nqSTvDHJed39qnlf4+DBg33jjTdmY2Mj6+vrS+/zXqU+86nP\nfLP18bTk7dmH5lOf+c6k+lTV/RrbLezMotPp7q6qUyZT3X11kquTzUHFbv2HeOWWH75Jcvhl60vf\n1pUXHctl29Rka3+29mUn+3um2e4HwoOp56r2mWVuZ5nOpB/Ee4m6r4a6s5tV1cOTvDfJO7v7fUnS\n3ffMLP/VJB9cUfcAgCVa9tPQ7qmq85Jkej+y5O0BAPAQTWeEvzXJrd395pn282Y+9sNJbtm6LgCw\n9y37zKLrk1ye5Krp/QNL3h4AAA/dM5O8PMnHq+rmqe2nk7y0qi7O5mVoh5P82Gq6BwAs08LCoqp6\ndzZvZv24qrojyc9nMyS6rqpeneT2JJctansAACxHd/9uktpm0W/sdF8AgJ23yKehvfQUiy5Z1DYA\nAAAAWK4du8H1buDJAOxWW/fN5OT90/4LAADATlj2Da4BAAAA2EOERQAAAAAMwiIAAAAABmERAAAA\nAIOwCAAAAIBBWAQAAADAICwCAAAAYBAWAQAAADAIiwAAAAAYhEUAAADA/9/e3YbKdp11AP8/3tRW\no7WVlhJzg4kQC9JAKiUihRKo1YsNjYpICpbGF6pgSsWAvdUP1m/xFT8ohZpGo4aG0CqGpKWmtKCC\ntbG1apM0eomV3JA2SikaBcOtjx9mZ2dycmfuOZczr/v3g8Od2TOw1/nPc2bWXbPWXjAyWAQAAADA\n6JJNN2AfXXn6/hcc++Jtb176nIOPwzY7TI0DAACwm8wsAgAAAGBksAgAAACAkcEiAAAAAEYGiwAA\nAAAYGSwCAAAAYGQ3NIAdZEc6AABgVcwsAgAAAGBksAgAAACAkcEiAAAAAEYGiwAAAAAYGSwCAAAA\nYGQ3NOAFDu60ZZeti2fXMgAAYNeYWQQAAADAyGARAAAAACODRQAAAACMDBYBAAAAMDJYBAAAAMDI\nbmgAW+g4dqQ7zE5szz7n1mvO5ebT99upDQC4aHbUhf1hZhEAAAAAI4NFAAAAAIwMFgEAAAAwMlgE\nAAAAwMhgEQAAAAAjg0UAAAAAjC7ZdAPYTra93F9e25njymEKea7rdzx4nlWeCwAAWMxgEQAAAEtN\n4Qsy4DmWoQEAAAAwMrMIAADYO5Y376bDvG5eW1g9M4sAAAAAGJlZBAAA7JTjmlmya9fh2bX2MrNt\nM6HUEYdhsGjOtv0Rw9Rcefr+3HrNudw897e4yY6fD9LpuJgp7+erBzvHAQCwDyxDAwAAAGBkZhEA\nAGypfZzluo+/067xGszIARYzswgAAACAkZlFAABwzI56LbRbrzmX61fdKNgCuzabZ9fay8VzTcjn\nM7MIAAAAgJGZRVyUdW5Xamer/XEcr4ER/+20TTuFbbvDzCSQFQAAm2SwCAAAdtg2fRkz1cHuC/3e\nR12WuOg563S+9nB+U637C7mYul/VF47b9ve1C9ayDK2qTlXVo1V1pqpOr+OcAACshr4dAOy3lc8s\nqqoTSX4vyZuSnE3yYFXd290Pr/rcAAAcr23p263qW+JdnAGyLuucPXHwXH946tKVnetCzBrZTdtU\nQ4exTe8r3gcXO66ZUIeZubfpPNcxs+i6JGe6+7HufibJ3UluXMN5AQA4fvp2ALDn1jFYdHmSx+fu\nnx2OAQCwe/TtAGDPVXev9gRVP5rkVHf/9HD/bUm+p7tvOfC8dyR5x3D31UkeXWnDds8rkvzHphsx\nMTLfDLlvhtw3Yxdy//bufuWmG8H2OEzfbkG/bhfqfZPks5x8lpPPhcloOfkst0/5HKpvt47d0J5I\ncsXc/ZPDsefp7vcnef8a2rOTqurvuvt1m27HlMh8M+S+GXLfDLmzoy7Ytztfv069Lyef5eSznHwu\nTEbLyWe5KeazjmVoDya5uqquqqqvT3JTknvXcF4AAI6fvh0A7LmVzyzq7nNVdUuSjyU5keSO7n5o\n1ecFAOD46dsBwP5bxzK0dPdHknxkHefaY5borZ/MN0PumyH3zZA7O+ki+3bqfTn5LCef5eRzYTJa\nTj7LTS6flV/gGgAAAIDdsY5rFgEAAACwIwwWbbGq+o2q+kJV/WNV/VlVvWzusfdU1ZmqerSqfmCT\n7dxHVXVqyPZMVZ3edHv2VVVdUVWfrKqHq+qhqnrXcPxbq+qBqvqX4d+Xb7qt+6aqTlTV31fVfcN9\nma9YVb2sqj40vK8/UlXfK3f2SVXdUVVPVdXn544trPGp9WUW5PPeqnqiqj43/Pzg3GNTy+fIfYIp\nZbQkHzWUpKpeUlWfrqp/GPL51eG4+snSfNTPnKP0j6eQj2VoW6yqvj/JJ4YLSf5aknT3u6vqu5J8\nMMl1Sb4tyceTfGd3f21zrd0fVXUiyT8neVOSs5nt+vLW7n54ow3bQ1V1WZLLuvuzVfXNST6T5IeS\n3JzkK9192zBY9/LufvcGm7p3quoXkrwuyUu7+4aq+vXIfKWq6s4kf9Xdt9dsB6lvTPJLkTt7oqre\nkOTpJH/U3a8Zjp33vWWKfZkF+bw3ydPd/ZsHnjvFfI7UJ5haRkvy+bGooVRVJbm0u5+uqhcl+esk\n70ryI1E/y/I5FfUzOmz/eCr5mFm0xbr7L7r73HD3U0lODrdvTHJ3d/9vd/9rkjOZFSrH47okZ7r7\nse5+JsndmWXOMevuJ7v7s8Pt/0rySJLLM8v7zuFpd2bWGeKYVNXJJG9OcvvcYZmvUFV9S5I3JPlA\nknT3M9391cidPdLdf5nkKwcOL6rxyfVlFuSzyBTzOWqfYFIZLclnkanl09399HD3RcNPR/0kWZrP\nIpPKJzly/3gS+Rgs2h0/meSjw+3Lkzw+99jZLP+w4GjkuwFVdWWS1yb52ySv6u4nh4e+lORVG2rW\nvvqdJL+Y5P/mjsl8ta5K8u9J/mCY3nx7VV0aubP/FtW4z9rnvLNmlxy4Y26Jw6TzOWSfYLIZHcgn\nUUNJxiVEn0vyVJIHulv9zFmQT6J+nnWU/vEk8jFYtGFV9fGq+vx5fm6ce84vJzmX5K7NtRRWp6q+\nKcmHk/x8d//n/GM9WytrvewxqaobkjzV3Z9Z9ByZr8QlSb47yfu6+7VJ/jvJ866HJnf2nRo/r/cl\n+Y4k1yZ5MslvbbY5m6dPsNx58lFDg+7+Wndfm9lqjOuq6jUHHp90/SzIR/1E/3iRSzbdgKnr7u9b\n9nhV3ZzkhiRv7OcuMPVEkivmnnZyOMbxkO8aDeumP5zkru7+0+Hwl6vqsu5+clij/9TmWrh3Xp/k\nLcMFDF+S5KVV9SeR+aqdTXJ27lu8D2U2WCR39t2iGvdZm6S7v/zs7ar6/ST3DXcnmc8R+wSTy+h8\n+aihF+rur1bVJzO7Ho/6OWA+n/lrFU28fo7aP55EPmYWbbGqOpXZVLi3dPf/zD10b5KbqurFVXVV\nkquTfHoTbdxTDya5uqquGi5Ce1NmmXPMhovtfSDJI93923MP3Zvk7cPttyf583W3bV9193u6+2R3\nX5lZbX+iu388Ml+p7v5Skser6tXDoTcmeThyZ/8tqnF9mYwXLX7WDyd5dqe0yeVzEX2CSWW0KB81\nNFNVr6xh5+iq+obMNqr5QtRPksX5qJ+Zi+gfTyIfM4u22+8meXGSB2afD/lUd/9sdz9UVfdk9h+N\nc0l+bt+uvL5JPdt97pYkH0tyIskd3f3Qhpu1r16f5G1J/mlYQ53Mdoe6Lck9VfVTSf4ts50+WC2Z\nr947k9w1DEI/luQnMvvSRu7shar6YJLrk7yiqs4m+ZUseG+ZYl9mQT7XV9W1mS1t+GKSn0mmmU+O\n2CeYYEaL8nmrGkqSXJbkzprtavx1Se7p7vuq6m+ifpLF+fyx+llq0u8/9dzKJgAAAACmzjI0AAAA\nAEYGiwAAAAAYGSwCAAAAYGSwCAAAAICRwSIAAAAARgaLAAAAABgZLAIAAABgZLAIAAAAgNH/A8iY\nacG7CAjCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27591780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_to_analyse.hist(bins=100, figsize = [20,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распределения данных признаков не похожи на нормальное, а также не похожи между собой. При этом признак Var19 имеет наибольшее количество различных значений. Признаки Var37 и Var57 имеют выбросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var19</th>\n",
       "      <th>Var21</th>\n",
       "      <th>Var37</th>\n",
       "      <th>Var57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.516340</td>\n",
       "      <td>38.909941</td>\n",
       "      <td>2.557630</td>\n",
       "      <td>232.787813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.755372</td>\n",
       "      <td>144.336454</td>\n",
       "      <td>9.740796</td>\n",
       "      <td>56.763970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.617564</td>\n",
       "      <td>198.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.617564</td>\n",
       "      <td>253.140675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>253.140675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>218.000000</td>\n",
       "      <td>2527.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>636.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Var19        Var21       Var37       Var57\n",
       "count  612.000000   612.000000  612.000000  612.000000\n",
       "mean    45.516340    38.909941    2.557630  232.787813\n",
       "std     34.755372   144.336454    9.740796   56.763970\n",
       "min      4.000000     0.000000  -20.000000  114.000000\n",
       "25%     18.000000     0.000000    1.617564  198.000000\n",
       "50%     36.000000     0.000000    1.617564  253.140675\n",
       "75%     60.000000    21.000000    4.000000  253.140675\n",
       "max    218.000000  2527.000000   66.000000  636.000000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смотрим объекты, на которых возникает ошибка по классу неотток\n",
    "X_test_frame_non_churn = X_test_frame.loc[index_non_churn_error]\n",
    "X_to_analyse2 = X_test_frame_non_churn[['Var19', 'Var21', 'Var37', 'Var57']]\n",
    "X_to_analyse2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   4.,    6.,    8.,   10.,   12.,   14.,   16.,   18.,   20.,\n",
       "         22.,   24.,   26.,   28.,   30.,   32.,   34.,   36.,   38.,\n",
       "         40.,   42.,   44.,   46.,   48.,   50.,   52.,   54.,   56.,\n",
       "         58.,   60.,   62.,   64.,   66.,   68.,   70.,   72.,   74.,\n",
       "         76.,   78.,   80.,   82.,   84.,   86.,   88.,   90.,   92.,\n",
       "         94.,   96.,   98.,  100.,  102.,  104.,  106.,  108.,  110.,\n",
       "        112.,  114.,  116.,  118.,  120.,  124.,  126.,  128.,  130.,\n",
       "        132.,  134.,  136.,  140.,  146.,  150.,  154.,  156.,  162.,\n",
       "        192.,  198.,  218.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_to_analyse2['Var19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     7.        ,    14.        ,    21.        ,\n",
       "          28.        ,    35.        ,    42.        ,    49.        ,\n",
       "          56.        ,    63.        ,    70.        ,    80.99647234,\n",
       "          84.        ,    91.        ,    98.        ,   105.        ,\n",
       "         112.        ,   119.        ,   126.        ,   140.        ,\n",
       "         154.        ,   161.        ,   168.        ,   175.        ,\n",
       "         189.        ,   196.        ,   203.        ,   210.        ,\n",
       "         224.        ,   231.        ,   238.        ,   245.        ,\n",
       "         252.        ,   259.        ,   322.        ,   336.        ,\n",
       "         343.        ,   385.        ,   413.        ,   434.        ,\n",
       "         441.        ,   483.        ,   490.        ,   497.        ,\n",
       "         679.        ,   980.        ,  1092.        ,  1134.        ,\n",
       "        2527.        ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_to_analyse2['Var21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-20.        , -18.        , -14.        , -12.        ,\n",
       "       -10.        ,  -8.        ,  -6.        ,  -4.        ,\n",
       "        -2.        ,   0.        ,   1.61756446,   2.        ,\n",
       "         4.        ,   6.        ,   8.        ,  10.        ,\n",
       "        12.        ,  14.        ,  16.        ,  18.        ,\n",
       "        20.        ,  22.        ,  24.        ,  26.        ,\n",
       "        28.        ,  30.        ,  32.        ,  34.        ,\n",
       "        36.        ,  38.        ,  40.        ,  44.        ,\n",
       "        46.        ,  62.        ,  66.        ])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_to_analyse2['Var37'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 114.        ,  120.        ,  126.        ,  132.        ,\n",
       "        138.        ,  144.        ,  150.        ,  156.        ,\n",
       "        162.        ,  168.        ,  174.        ,  180.        ,\n",
       "        186.        ,  192.        ,  198.        ,  204.        ,\n",
       "        210.        ,  216.        ,  222.        ,  228.        ,\n",
       "        234.        ,  240.        ,  246.        ,  252.        ,\n",
       "        253.14067524,  258.        ,  264.        ,  270.        ,\n",
       "        276.        ,  282.        ,  288.        ,  294.        ,\n",
       "        300.        ,  306.        ,  312.        ,  318.        ,\n",
       "        324.        ,  330.        ,  336.        ,  342.        ,\n",
       "        354.        ,  360.        ,  402.        ,  408.        ,\n",
       "        450.        ,  498.        ,  636.        ])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_to_analyse2['Var57'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "49\n",
      "35\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print (len(np.unique(X_to_analyse2['Var19'])))\n",
    "print (len(np.unique(X_to_analyse2['Var21'])))\n",
    "print (len(np.unique(X_to_analyse2['Var37'])))\n",
    "print (len(np.unique(X_to_analyse2['Var57'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения данных признаков на ошибках класса неотток практически сопоставимо со значениями аналогичных признаков на ошибках класса отток. \n",
    "1. Значения Var19 практически представляют собой арифметическую прогрессию с шагом 2\n",
    "2. Значения Var21 практически представляют собой арифметическую прогрессию с шагом 7\n",
    "3. Значения Var37 практически представляют собой арифметическую прогрессию с шагом 2, но с минимальным значением -20\n",
    "4. Значения Var57 практически представляют собой арифметическую прогрессию с шагом 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000000026D096A0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000000027350080>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000000026E9FE10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000000273BB128>]], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIgAAARuCAYAAAC4MQxcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x272c1048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_to_analyse2.hist(bins=100, figsize = [20,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Преобразования для финальной модели описаны и проведены в пункте 6. Напомним их:\n",
    "\n",
    "1. Балансировка классов методом undersampling (с одинаковыми долями каждого класса)\n",
    "2. Заполнение пропущенных вещественных значений на средние по столбцам\n",
    "3. Обработка категориальных признаков DictVectorizer'ом\n",
    "4. Отбор признаков с использованием решающего дерева\n",
    "5. Окончательный отбор признаков с помощью метода feature_importances_\n",
    "6. Подбор параметров по сетке (перебор количества эстиматоров и максимальной глубины дерева)\n",
    "7. В итоге получилась модель градиентного бустинга на 70 деревьев с макс глубиной 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Можно попробовать отмасштабировать признаки (но в случае градиентного бустинга это не сильно изменить качество модели), а также их нормализовать"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

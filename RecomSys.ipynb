{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('C:\\Users\\horch\\Desktop\\Data mining\\Course 5\\_coursera_sessions_test.txt', sep = ';', header = 0)\n",
    "train_data = pd.read_csv('C:\\Users\\horch\\Desktop\\Data mining\\Course 5\\_coursera_sessions_train.txt', sep = ';', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# сплитим сессии и получаем список просмотров\n",
    "split=[]\n",
    "for i in train_data['0,1,2,3,4,5']:\n",
    "    split.append(i.split(','))\n",
    "items = []\n",
    "for i in split:\n",
    "    for j in i:\n",
    "        items.append(j)  \n",
    "# словарь частот просмотров\n",
    "dct = {}\n",
    "for i in items:\n",
    "    if i in dct:\n",
    "        dct[i] += 1\n",
    "    else:\n",
    "        dct[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# создаем словарь частот покупок\n",
    "split_buy = []\n",
    "for i in train_data['Unnamed: 1'].dropna():\n",
    "    split_buy.append(i.split(','))\n",
    "\n",
    "items_buy = []\n",
    "for i in split_buy:\n",
    "    for j in i:\n",
    "        items_buy.append(j)\n",
    "dct_buy = {}\n",
    "for i in items_buy:\n",
    "    if i in dct_buy:\n",
    "        dct_buy[i] += 1\n",
    "    else:\n",
    "        dct_buy[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_list_buy = []\n",
    "for i in split_buy: #выбираем сессию\n",
    "    a = []\n",
    "    for j in i: \n",
    "        a.append((j,dct_buy.get(j)))\n",
    "    train_list_buy.append(a)    \n",
    "\n",
    "sort_train_buy=[]\n",
    "for i in xrange(len(train_list_buy)):\n",
    "    sort_train_buy.append(pd.unique(sorted(train_list_buy[i], key=lambda x: x[1], reverse = True)))\n",
    "# получили отсортированный массив покупок без дублей по сессиям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([('63', 6), ('64', 3), ('60', 2), ('61', 2), ('65', 2), ('66', 2),\n",
       "        ('67', 2), ('68', 2), ('59', 1), ('62', 1)], dtype=object),\n",
       " array([('85', 165), ('93', 94), ('89', 19), ('90', 13), ('84', 12),\n",
       "        ('92', 12), ('86', 10), ('87', 4), ('91', 2), ('88', 1)], dtype=object),\n",
       " array([('127', 101), ('138', 33), ('198', 24), ('199', 21)], dtype=object)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_na=train_data.dropna() #удаляем сессии, в которых ничего не купили\n",
    "\n",
    "# сплитим сессии и получаем список просмотров\n",
    "split_drop_na=[]\n",
    "for i in train_data_na['0,1,2,3,4,5']:\n",
    "    split_drop_na.append(i.split(','))\n",
    "\n",
    "train_list = []\n",
    "for i in split_drop_na: \n",
    "    a = []\n",
    "    for j in i: \n",
    "        a.append((j,dct.get(j)))\n",
    "    train_list.append(a)    \n",
    "train_list\n",
    "sort_train_na=[]\n",
    "for i in xrange(len(train_list)):\n",
    "    sort_train_na.append(pd.unique(sorted(train_list[i], key=lambda x: x[1], reverse = True)))\n",
    "sort_train_na[:3]\n",
    "# получили отсортированный массив просмотров с частотами просмотров без дублей по сессиям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['67', '60', '63'], ['86'], ['199'], ['303'], ['352']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#формируем итоговые списки покупок и просмотров\n",
    "itog_prosm=[]\n",
    "for i in sort_train_na:\n",
    "    b=[]\n",
    "    for j in i:\n",
    "        b.append(j[0])\n",
    "    itog_prosm.append(b)    \n",
    "    \n",
    "itog_pok=[]\n",
    "for i in sort_train_buy:\n",
    "    b=[]\n",
    "    for j in i:\n",
    "        b.append(j[0])\n",
    "    itog_pok.append(b)\n",
    "    \n",
    "itog_pok[:5]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3608"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# массив рекомендаций при к=5\n",
    "rec_5=[]\n",
    "for i in itog_prosm:\n",
    "    r = []\n",
    "    for j in xrange(min(5, len(i))):\n",
    "        r.append(i[j])\n",
    "    rec_5.append(r) \n",
    "# массив рекомендаций при к=1    \n",
    "rec_1=[]\n",
    "for i in itog_prosm:\n",
    "    r = []\n",
    "    for j in xrange(min(1, len(i))):\n",
    "        r.append(i[j])\n",
    "    rec_1.append(r)    \n",
    "    \n",
    "#купленные товары из рекомендованных при k=5:\n",
    "result_5=[]\n",
    "for i in xrange(len(rec_5)):\n",
    "    result_5.append(list(set(rec_5[i]) & set(itog_pok[i])))\n",
    "#купленные товары из рекомендованных при k=5:\n",
    "result_1=[]\n",
    "for i in xrange(len(rec_1)):\n",
    "    result_1.append(list(set(rec_1[i]) & set(itog_pok[i])))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.442634316595 0.512195121951 0.824691824713 0.212527716186\n"
     ]
    }
   ],
   "source": [
    "prec_5=[]\n",
    "prec_1=[]\n",
    "for i in xrange(len(result_5)):\n",
    "    prec_5.append(len(result_5[i])/5.)\n",
    "    prec_1.append(len(result_1[i]))\n",
    "\n",
    "recall_5=[]\n",
    "recall_1=[]\n",
    "for i in xrange(len(result_5)):\n",
    "    recall_5.append(len(result_5[i])/float(len(itog_pok[i])))\n",
    "    recall_1.append(len(result_1[i])/float(len(itog_pok[i])))\n",
    "    \n",
    "train_AR_1 = np.mean(recall_1)\n",
    "train_AP_1 = np.mean(prec_1)\n",
    "train_AR_5 = np.mean(recall_5)\n",
    "train_AP_5 = np.mean(prec_5)\n",
    "\n",
    "print train_AR_1, train_AP_1, train_AR_5, train_AP_5   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([('60', 1), ('63', 1), ('67', 1), ('59', None), ('61', None),\n",
       "        ('62', None), ('64', None), ('65', None), ('66', None), ('68', None)], dtype=object),\n",
       " array([('86', 2), ('85', 1), ('93', 1), ('84', None), ('87', None),\n",
       "        ('88', None), ('89', None), ('90', None), ('91', None), ('92', None)], dtype=object),\n",
       " array([('138', 1), ('199', 1), ('127', 1), ('198', None)], dtype=object)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сортировка по частоте в покупках:\n",
    "train_list = []\n",
    "for i in split_drop_na: \n",
    "    a = []\n",
    "    for j in i: \n",
    "        a.append((j,dct_buy.get(j)))\n",
    "    train_list.append(a)    \n",
    "\n",
    "train_buy=[]\n",
    "for i in xrange(len(train_list)):\n",
    "    train_buy.append(pd.unique(sorted(train_list[i], key=lambda x: x[1], reverse = True)))\n",
    "train_buy[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itog_prosm_buy=[]\n",
    "for i in train_buy:\n",
    "    b=[]\n",
    "    for j in i:\n",
    "        b.append(j[0])\n",
    "    itog_prosm_buy.append(b)\n",
    "# массив рекомендаций при к=5\n",
    "rec_buy_5=[]\n",
    "for i in itog_prosm_buy:\n",
    "    r = []\n",
    "    for j in xrange(min(5, len(i))):\n",
    "        r.append(i[j])\n",
    "    rec_buy_5.append(r) \n",
    "# массив рекомендаций при к=1    \n",
    "rec_buy_1=[]\n",
    "for i in itog_prosm_buy:\n",
    "    r = []\n",
    "    for j in xrange(min(1, len(i))):\n",
    "        r.append(i[j])\n",
    "    rec_buy_1.append(r)    \n",
    "    \n",
    "#купленные товары из рекомендованных при k=5:\n",
    "result_buy_5=[]\n",
    "for i in xrange(len(rec_buy_5)):\n",
    "    result_buy_5.append(list(set(rec_buy_5[i]) & set(itog_pok[i])))\n",
    "#купленные товары из рекомендованных при k=1:\n",
    "result_buy_1=[]\n",
    "for i in xrange(len(rec_buy_1)):\n",
    "    result_buy_1.append(list(set(rec_buy_1[i]) & set(itog_pok[i])))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69 0.8 0.93 0.25\n"
     ]
    }
   ],
   "source": [
    "prec_buy_5=[]\n",
    "prec_buy_1=[]\n",
    "for i in xrange(len(result_buy_5)):\n",
    "    prec_buy_5.append(len(result_buy_5[i])/5.)\n",
    "    prec_buy_1.append(len(result_buy_1[i]))\n",
    "\n",
    "recall_buy_5=[]\n",
    "recall_buy_1=[]\n",
    "for i in xrange(len(result_buy_5)):\n",
    "    recall_buy_5.append(len(result_buy_5[i])/float(len(itog_pok[i])))\n",
    "    recall_buy_1.append(len(result_buy_1[i])/float(len(itog_pok[i])))\n",
    "    \n",
    "train_AR_buy_1 = np.mean(recall_buy_1)\n",
    "train_AP_buy_1 = np.mean(prec_buy_1)\n",
    "train_AR_buy_5 = np.mean(recall_buy_5)\n",
    "train_AP_buy_5 = np.mean(prec_buy_5)\n",
    "\n",
    "print round(train_AR_buy_1, 2), round(train_AP_buy_1,2), round(train_AR_buy_5,2), round(train_AP_buy_5,2)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестовая часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6,7,8</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13,14,15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22,23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28,29,30,31,32,33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40,41</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43,44,43,45,43,45,43,46</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50,51,47,52,49,53,54,55,56,57,58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63,68,69,70,66,61,59,61,66,68</td>\n",
       "      <td>66,63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79,80,81,82,83</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94,95,94,96,97,98,99,100,101,80,102,103,104,10...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>125,126,127,128</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>135,136</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>145,146,147,148,149,150,151,152,153,154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>158,159,160,159,161,162</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>167,168,169,170,79,171,170,79,172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                6,7,8 Unnamed: 1\n",
       "0                                            13,14,15        NaN\n",
       "1                                               22,23        NaN\n",
       "2                                   28,29,30,31,32,33        NaN\n",
       "3                                               40,41        NaN\n",
       "4                             43,44,43,45,43,45,43,46        NaN\n",
       "5                    50,51,47,52,49,53,54,55,56,57,58        NaN\n",
       "6                       63,68,69,70,66,61,59,61,66,68      66,63\n",
       "7                                                  75        NaN\n",
       "8                                      79,80,81,82,83        NaN\n",
       "9   94,95,94,96,97,98,99,100,101,80,102,103,104,10...        NaN\n",
       "10                                    125,126,127,128        NaN\n",
       "11                                            135,136        NaN\n",
       "12            145,146,147,148,149,150,151,152,153,154        NaN\n",
       "13                            158,159,160,159,161,162        162\n",
       "14                  167,168,169,170,79,171,170,79,172        NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([('63', 6), ('68', 2), ('66', 2), ('61', 2), ('59', 1), ('69', None),\n",
       "        ('70', None)], dtype=object),\n",
       " array([('158', 641), ('162', 318), ('160', 92), ('159', 81), ('161', 74)], dtype=object),\n",
       " array([('204', 396), ('202', 66), ('203', 19), ('200', 18), ('201', 12)], dtype=object)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_na=test_data.dropna() #удаляем сессии, в которых ничего не купили\n",
    "\n",
    "# список просмотров\n",
    "split_drop_na_test=[]\n",
    "for i in test_data_na['6,7,8']:\n",
    "    split_drop_na_test.append(i.split(','))\n",
    "\n",
    "# сптсок покупок\n",
    "split_buy_test=[]\n",
    "for i in test_data_na['Unnamed: 1']:\n",
    "    split_buy_test.append(i.split(','))    \n",
    "    \n",
    "    \n",
    "train_list_test = []\n",
    "for i in split_drop_na_test: \n",
    "    a = []\n",
    "    for j in i: \n",
    "        a.append((j,dct.get(j)))\n",
    "    train_list_test.append(a)    \n",
    "\n",
    "sort_test=[]\n",
    "for i in xrange(len(train_list_test)):\n",
    "    sort_test.append(pd.unique(sorted(train_list_test[i], key=lambda x: x[1], reverse = True)))\n",
    "sort_test[:3]\n",
    "# получили отсортированный массив просмотров с частотами просмотров без дублей по сессиям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#формируем итоговые списки просмотров\n",
    "itog_prosm_test=[]\n",
    "for i in sort_test:\n",
    "    b=[]\n",
    "    for j in i:\n",
    "        b.append(j[0])\n",
    "    itog_prosm_test.append(b)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# массив рекомендаций при к=5\n",
    "rec_5_test=[]\n",
    "for i in itog_prosm_test:\n",
    "    r = []\n",
    "    for j in xrange(min(5, len(i))):\n",
    "        r.append(i[j])\n",
    "    rec_5_test.append(r) \n",
    "# массив рекомендаций при к=1    \n",
    "rec_1_test=[]\n",
    "for i in itog_prosm_test:\n",
    "    r = []\n",
    "    for j in xrange(min(1, len(i))):\n",
    "        r.append(i[j])\n",
    "    rec_1_test.append(r)    \n",
    "    \n",
    "#купленные товары из рекомендованных при k=5:\n",
    "result_5_test=[]\n",
    "for i in xrange(len(rec_5_test)):\n",
    "    result_5_test.append(list(set(rec_5_test[i]) & set(split_buy_test[i])))\n",
    "#купленные товары из рекомендованных при k=5:\n",
    "result_1_test=[]\n",
    "for i in xrange(len(rec_1_test)):\n",
    "    result_1_test.append(list(set(rec_1_test[i]) & set(split_buy_test[i])))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42 0.48 0.8 0.2\n"
     ]
    }
   ],
   "source": [
    "prec_5_test=[]\n",
    "prec_1_test=[]\n",
    "for i in xrange(len(result_5_test)):\n",
    "    prec_5_test.append(len(result_5_test[i])/5.)\n",
    "    prec_1_test.append(len(result_1_test[i]))\n",
    "\n",
    "recall_5_test=[]\n",
    "recall_1_test=[]\n",
    "for i in xrange(len(result_5_test)):\n",
    "    recall_5_test.append(len(result_5_test[i])/float(len(split_buy_test[i])))\n",
    "    recall_1_test.append(len(result_1_test[i])/float(len(split_buy_test[i])))\n",
    "    \n",
    "train_AR_1_test = np.mean(recall_1_test)\n",
    "train_AP_1_test = np.mean(prec_1_test)\n",
    "train_AR_5_test = np.mean(recall_5_test)\n",
    "train_AP_5_test = np.mean(prec_5_test)\n",
    "\n",
    "print round(train_AR_1_test, 2), round(train_AP_1_test,2), round(train_AR_5_test,2), round(train_AP_5_test,2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([('63', 1), ('68', None), ('69', None), ('70', None), ('66', None),\n",
       "        ('61', None), ('59', None)], dtype=object),\n",
       " array([('158', 14), ('162', 8), ('160', 4), ('159', None), ('161', None)], dtype=object),\n",
       " array([('204', 12), ('202', 1), ('200', None), ('201', None), ('203', None)], dtype=object)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сортировка по частоте в покупках:\n",
    "test_list_buy = []\n",
    "for i in split_drop_na_test: \n",
    "    a = []\n",
    "    for j in i: \n",
    "        a.append((j,dct_buy.get(j)))\n",
    "    test_list_buy.append(a)    \n",
    "\n",
    "test_buy=[]\n",
    "for i in xrange(len(test_list_buy)):\n",
    "    test_buy.append(pd.unique(sorted(test_list_buy[i], key=lambda x: x[1], reverse = True)))\n",
    "test_buy[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itog_prosm_buy_test=[]\n",
    "for i in test_buy:\n",
    "    b=[]\n",
    "    for j in i:\n",
    "        b.append(j[0])\n",
    "    itog_prosm_buy_test.append(b)\n",
    "# массив рекомендаций при к=5\n",
    "rec_buy_5_test=[]\n",
    "for i in itog_prosm_buy_test:\n",
    "    r = []\n",
    "    for j in xrange(min(5, len(i))):\n",
    "        r.append(i[j])\n",
    "    rec_buy_5_test.append(r) \n",
    "# массив рекомендаций при к=1    \n",
    "rec_buy_1_test=[]\n",
    "for i in itog_prosm_buy_test:\n",
    "    r = []\n",
    "    for j in xrange(min(1, len(i))):\n",
    "        r.append(i[j])\n",
    "    rec_buy_1_test.append(r)    \n",
    "    \n",
    "#купленные товары из рекомендованных при k=5:\n",
    "result_buy_5_test=[]\n",
    "for i in xrange(len(rec_buy_5_test)):\n",
    "    result_buy_5_test.append(list(set(rec_buy_5_test[i]) & set(split_buy_test[i])))\n",
    "#купленные товары из рекомендованных при k=1:\n",
    "result_buy_1_test=[]\n",
    "for i in xrange(len(rec_buy_1_test)):\n",
    "    result_buy_1_test.append(list(set(rec_buy_1_test[i]) & set(split_buy_test[i])))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46 0.53 0.82 0.21\n"
     ]
    }
   ],
   "source": [
    "prec_buy_5_test=[]\n",
    "prec_buy_1_test=[]\n",
    "for i in xrange(len(result_buy_5_test)):\n",
    "    prec_buy_5_test.append(len(result_buy_5_test[i])/5.)\n",
    "    prec_buy_1_test.append(len(result_buy_1_test[i]))\n",
    "\n",
    "recall_buy_5_test=[]\n",
    "recall_buy_1_test=[]\n",
    "for i in xrange(len(result_buy_5_test)):\n",
    "    recall_buy_5_test.append(len(result_buy_5_test[i])/float(len(split_buy_test[i])))\n",
    "    recall_buy_1_test.append(len(result_buy_1_test[i])/float(len(split_buy_test[i])))\n",
    "    \n",
    "train_AR_buy_1_test = np.mean(recall_buy_1_test)\n",
    "train_AP_buy_1_test = np.mean(prec_buy_1_test)\n",
    "train_AR_buy_5_test = np.mean(recall_buy_5_test)\n",
    "train_AP_buy_5_test = np.mean(prec_buy_5_test)\n",
    "\n",
    "print round(train_AR_buy_1_test, 2), round(train_AP_buy_1_test,2), round(train_AR_buy_5_test,2), round(train_AP_buy_5_test,2) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
